{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter, defaultdict\n",
    "from typing import List\n",
    "import jieba\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import jieba\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from utils import BM25, filter_stop\n",
    "\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "llm = OllamaLLM(model=\"qwen2.5:1.5b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vector retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = '''You are a helpful assistant, please answer the following question based on the given content:\n",
    "\n",
    "Question:\n",
    "```\n",
    "{question}\n",
    "```\n",
    "\n",
    "Content:\n",
    "```\n",
    "{content}\n",
    "```\n",
    "\n",
    "Just give a simple answer, do not include any additional information or explaination.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wenjiazhai/miniconda3/envs/langchain/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embed = HuggingFaceEmbeddings(model_name='BAAI/bge-small-en-v1.5')\n",
    "vector_db = FAISS.load_local('/Users/wenjiazhai/Documents/GitHub/paper_analyze/store/vanilla_langchain', \n",
    "                             embed, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/77/tngzlz3n44s1cm7spj20fy8m0000gn/T/jieba.cache\n",
      "Loading model cost 0.398 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "all_documents = [doc.page_content for doc in vector_db.docstore._dict.values()]\n",
    "bm25 = BM25(all_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "314it [04:42,  1.11it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('../../data/LongBench_original.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "res = {'query': [], 'answer': [], 'predict': []}\n",
    "for q, a in tqdm(zip(data['query'], data['answer'])):\n",
    "    scores = defaultdict(int)\n",
    "    \n",
    "    bm25_retrival_res = bm25.query(q)[:12]\n",
    "    for doc, score in bm25_retrival_res:\n",
    "        scores[doc] += score * 0.4\n",
    "    vector_retrieval_res = vector_db.similarity_search_with_score(q, k=12)\n",
    "    for doc, score in vector_retrieval_res:\n",
    "        scores[doc.page_content] += score * 0.6\n",
    "    \n",
    "    scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    retrieval = '\\n'.join([x[0] for x in scores[:6]])\n",
    "    response = llm.invoke(prompt_template.format(question=q, content=retrieval))\n",
    "    res['query'].append(q)\n",
    "    res['answer'].append(a)\n",
    "    res['predict'].append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../output/hybrid.json', 'w') as f:\n",
    "    json.dump(res, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/wenjiazhai/Documents/GitHub/paper_analyze/output/hybrid/76.json error\n",
      "/Users/wenjiazhai/Documents/GitHub/paper_analyze/output/hybrid/308.json error\n",
      "/Users/wenjiazhai/Documents/GitHub/paper_analyze/output/hybrid/297.json error\n",
      "/Users/wenjiazhai/Documents/GitHub/paper_analyze/output/hybrid/151.json error\n",
      "/Users/wenjiazhai/Documents/GitHub/paper_analyze/output/hybrid/192.json error\n",
      "/Users/wenjiazhai/Documents/GitHub/paper_analyze/output/hybrid/219.json error\n",
      "/Users/wenjiazhai/Documents/GitHub/paper_analyze/output/hybrid/300.json error\n",
      "/Users/wenjiazhai/Documents/GitHub/paper_analyze/output/hybrid/195.json error\n",
      "/Users/wenjiazhai/Documents/GitHub/paper_analyze/output/hybrid/121.json error\n",
      "/Users/wenjiazhai/Documents/GitHub/paper_analyze/output/hybrid/273.json error\n"
     ]
    }
   ],
   "source": [
    "path = Path('/Users/wenjiazhai/Documents/GitHub/paper_analyze/output/hybrid').rglob('*.json')\n",
    "\n",
    "for file in path:\n",
    "    try:\n",
    "        with open(file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "    except:\n",
    "        print(f'{file} error')\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/Users/wenjiazhai/Documents/GitHub/paper_analyze/output/hybrid').rglob('*.json')\n",
    "\n",
    "data = []\n",
    "for file in path:\n",
    "    try:\n",
    "        with open(file, 'r') as f:\n",
    "            data.append(json.load(f))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('/Users/wenjiazhai/Documents/GitHub/paper_analyze/output/hybrid_output_consistency.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2138157894736842"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consistency = [int(d) for d in df['consistency']]\n",
    "sum(consistency) / len(consistency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
