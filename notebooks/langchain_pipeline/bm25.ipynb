{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "from typing import List\n",
    "import jieba\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import jieba\n",
    "from tqdm import tqdm\n",
    "from utils import BM25, filter_stop\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM25:\n",
    "    def __init__(self, corpus: List[List[str]], k1=1.5, b=0.75):\n",
    "        assert isinstance(corpus, list), \"Corpus must be a list of documents\"\n",
    "        assert all([isinstance(c, str) for c in corpus]), \"Corpus must be a list of strings\"\n",
    "        \n",
    "        tmp = []\n",
    "        for para in corpus:\n",
    "            filtered = filter_stop(jieba.lcut(para))\n",
    "            tmp.append([s for s in filtered if s != ' '])\n",
    "        \n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.corpus = dict((i, doc) for i, doc in enumerate(corpus))\n",
    "        self.doc_lengths = [len(doc) for doc in tmp]\n",
    "        self.avg_doc_length = sum(self.doc_lengths) / len(self.doc_lengths)\n",
    "        self.doc_count = len(corpus)\n",
    "        self.doc_term_freqs = [Counter(doc) for doc in tmp]\n",
    "        self.build_inverted_index()\n",
    "\n",
    "    def build_inverted_index(self):\n",
    "        self.inverted_index = {}\n",
    "        for doc_id, doc_term_freq in enumerate(self.doc_term_freqs):\n",
    "            for term, freq in doc_term_freq.items():\n",
    "                if term not in self.inverted_index:\n",
    "                    self.inverted_index[term] = []\n",
    "                self.inverted_index[term].append((doc_id, freq))\n",
    "\n",
    "    def idf(self, term):\n",
    "        doc_freq = len(self.inverted_index.get(term, []))\n",
    "        if doc_freq == 0:\n",
    "            return 0\n",
    "        return math.log((self.doc_count - doc_freq + 0.5) / (doc_freq + 0.5) + 1.0)\n",
    "\n",
    "    def bm25_score(self, query_terms, doc_id):\n",
    "        score = 0\n",
    "        doc_length = self.doc_lengths[doc_id]\n",
    "        for term in query_terms:\n",
    "            tf = self.doc_term_freqs[doc_id].get(term, 0)\n",
    "            idf = self.idf(term)\n",
    "            numerator = tf * (self.k1 + 1)\n",
    "            denominator = tf + self.k1 * (1 - self.b + self.b * (doc_length / self.avg_doc_length))\n",
    "            score += idf * (numerator / denominator)\n",
    "        return score\n",
    "\n",
    "    def query(self, query):\n",
    "        query_terms = [w.lower() for w in jieba.cut(query) if w.lower() != ' ']\n",
    "        docs_w_scores = [(self.corpus[doc_id], self.bm25_score(query_terms, doc_id)) for doc_id in self.corpus.keys()]\n",
    "        sorted_docs_by_scores = sorted(docs_w_scores, key=lambda x: x[1], reverse=True)\n",
    "        return sorted_docs_by_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = '''You are a helpful assistant, please answer the following question based on the given content:\n",
    "\n",
    "Question:\n",
    "```\n",
    "{question}\n",
    "```\n",
    "\n",
    "Content:\n",
    "```\n",
    "{content}\n",
    "```\n",
    "\n",
    "Just give a simple answer, do not include any additional information or explaination.\n",
    "'''\n",
    "\n",
    "qa_instruction = '''\n",
    "You are an expert in information evaluation and critical thinking. Your task is to find the answer to a given question from a passage of text. You must carefully read every word and think through each step without overlooking any details. Your output should contain two fields: `Reasoning` and `Response`. In `Reasoning`, document your logical thought process in a clear, concise manner. If you find the answer, write it in the `Response` field; if not, try your best to guess one. The `Reasoning` should end with '*' to indicate completion.\n",
    "\n",
    "Objective: The task is to carefully analyze a passage of text to determine whether it contains the answer to a given question. The evaluation must be detailed, with clear reasoning, and identify the correct answer if present, or confirm its absence.\n",
    "\n",
    "You are provided with the following inputs:\n",
    "\n",
    "1. Context: {question}\n",
    "2. Question: {content}\n",
    "\n",
    "Based on these inputs, provide a step-by-step explanation to identify the correct answer from the content. If you cannot find the answer in the passage, try to guess the answer. Your response should only contain the answer itself. Do not explain, provide notes, or include any additional text, punctuation, or preposition (e.g., 'on', 'at'), or articles (e.g., 'a', 'an', 'the') unless absolutely necessary.\n",
    "\n",
    "Output format: \n",
    "\n",
    "-----\n",
    "SCHEMA\n",
    "-----\n",
    "\n",
    "{{\n",
    "    \"Reasoning\": \"Step-by-step reasoning explaining how the answer is inferenced to satisfy the question.\",\n",
    "    \"Response\": \"The answer itself, as simple as possible.\"\n",
    "}}\n",
    "\n",
    "-----\n",
    "\n",
    "1. Context: ```Pilotwings 64\\nPilotwings 64 (Japanese: パイロットウイングス64, Hepburn: Pairottouingusu Rokujūyon) is a video game for the Nintendo 64, originally released in 1996 along with the debut of the console. The game was co-developed by Nintendo and the American visual technology group Paradigm Simulation. It was one of three launch titles for the Nintendo 64 in Japan as well as Europe and one of two launch titles in North America. Pilotwings 64 is a follow-up to Pilotwings for the Super Nintendo Entertainment System (SNES), which was a North American launch game for its respective console in 1991. Also like that game, Pilotwings 64 received production input from Nintendo producer Shigeru Miyamoto.```\n",
    "2. Question: Who is a Japanese video game designer and producer, currently serving as the co-Representative Director of Nintendo, who gave production input to a video game for the Nintendo 64, originally released in 1996 along with the debut of the console?\n",
    "\n",
    "-----\n",
    "\n",
    "output:\n",
    "\n",
    "{{\n",
    "    \"Reasoning\": \"The context mentions that 'Pilotwings 64' was a video game released in 1996 for the Nintendo 64. The game received production input from Nintendo producer Shigeru Miyamoto. This aligns with the question, which asks for a Japanese video game designer and producer who gave production input to a Nintendo 64 game released in 1996. Additionally, Shigeru Miyamoto is well known as a prominent figure at Nintendo and is currently serving as the co-Representative Director of the company. Therefore, the content fully supports that Shigeru Miyamoto is the correct answer to the question.*\", \n",
    "    \"Response\": \"Shigeru Miyamoto\" \n",
    "}}\n",
    "\n",
    "-----\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/LongBench_original.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wenjiazhai/miniconda3/envs/langchain/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embed = HuggingFaceEmbeddings(model_name='BAAI/bge-small-en-v1.5')\n",
    "faiss_index = FAISS.load_local('/Users/wenjiazhai/Documents/GitHub/paper_analyze/store/vanilla_langchain', \n",
    "                               embed, allow_dangerous_deserialization=True)\n",
    "all_documents = [doc.page_content for doc in faiss_index.docstore._dict.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/77/tngzlz3n44s1cm7spj20fy8m0000gn/T/jieba.cache\n",
      "Loading model cost 0.386 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "bm25 = BM25(all_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "llm = OllamaLLM(model=\"qwen2.5:0.5b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "314it [03:54,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "k = 6\n",
    "\n",
    "res = {'query': [], 'answer': [], 'predict': []}\n",
    "for q, a in tqdm(zip(data['query'], data['answer'])):\n",
    "    retrieval = '\\n'.join([retr[0] for retr in bm25.query(q)[:k]])\n",
    "    response = llm.invoke(prompt_template.format(question=q, content=retrieval))\n",
    "    res['query'].append(q)\n",
    "    res['answer'].append(a)\n",
    "    res['predict'].append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../output/bm25_output.json', 'w') as f:\n",
    "    json.dump(res, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/wenjiazhai/Documents/GitHub/paper_analyze/output/BM25/103.json error\n",
      "/Users/wenjiazhai/Documents/GitHub/paper_analyze/output/BM25/174.json error\n",
      "/Users/wenjiazhai/Documents/GitHub/paper_analyze/output/BM25/162.json error\n",
      "/Users/wenjiazhai/Documents/GitHub/paper_analyze/output/BM25/95.json error\n",
      "/Users/wenjiazhai/Documents/GitHub/paper_analyze/output/BM25/227.json error\n",
      "/Users/wenjiazhai/Documents/GitHub/paper_analyze/output/BM25/231.json error\n",
      "/Users/wenjiazhai/Documents/GitHub/paper_analyze/output/BM25/220.json error\n",
      "/Users/wenjiazhai/Documents/GitHub/paper_analyze/output/BM25/26.json error\n",
      "/Users/wenjiazhai/Documents/GitHub/paper_analyze/output/BM25/108.json error\n",
      "/Users/wenjiazhai/Documents/GitHub/paper_analyze/output/BM25/117.json error\n",
      "/Users/wenjiazhai/Documents/GitHub/paper_analyze/output/BM25/249.json error\n",
      "/Users/wenjiazhai/Documents/GitHub/paper_analyze/output/BM25/157.json error\n",
      "/Users/wenjiazhai/Documents/GitHub/paper_analyze/output/BM25/9.json error\n"
     ]
    }
   ],
   "source": [
    "path = Path('/Users/wenjiazhai/Documents/GitHub/paper_analyze/output/BM25').rglob('*.json')\n",
    "\n",
    "for file in path:\n",
    "    try:\n",
    "        with open(file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "    except:\n",
    "        print(f'{file} error')\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/Users/wenjiazhai/Documents/GitHub/paper_analyze/output/BM25').rglob('*.json')\n",
    "\n",
    "data = []\n",
    "for file in path:\n",
    "    try:\n",
    "        with open(file, 'r') as f:\n",
    "            data.append(json.load(f))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('/Users/wenjiazhai/Documents/GitHub/paper_analyze/output/bh25_output_consistency.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19601328903654486"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consistency = [int(d) for d in df['consistency']]\n",
    "sum(consistency) / len(consistency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
