{
    "query": [
        "Is the ISR necessary for transgene reactivation?",
        "What experimental techniques were used to study the quantum dot structures in this research?",
        "What is the purpose of an ICD?",
        "Why is it important for the sides of the fuselage to be sloped (tumbled home)?",
        "How is electricity used in everyday life?",
        "What was Hugh H. Goodwin's rank in the United States Navy?",
        "What are the three synthetic types of vitamin K?",
        "Can individual molecules of indeno[1,2-a]fluorene switch between open-shell and closed-shell states?",
        "What field does Danny work in in Tennessee?",
        "What is the recommended daily intake of vitamin K for adult women and men?",
        "What is the SI unit of power?",
        "What is the main advantage of a horizontal business model for mobile devices?",
        "Who was Brooksley Elizabeth's first husband?",
        "What is the main methodology used in the research?",
        "How is the function beta(r) determined in the derivation?",
        "What is the water depth in the Greater Ekofisk Area?",
        "What were the vaccines trialed against?",
        "What size chains were used in the benchmarking?",
        "How many experiments were demonstrated to test the capabilities of the controller?",
        "What are the three teams that used conflict optimization in the challenge?",
        "What did the court in In re Ferguson conclude about the transformation prong of the Bilski test?",
        "How does the transition probability of the environment affect the learning rate in the static agent?",
        "What kind of ultracold neutral plasmas does this study focus on?",
        "What types of sensors are now capable of estimating physical activity levels and physiological outcomes of older adults?",
        "What did Mary tell the disciples?",
        "What is the future direction mentioned in the conclusion?",
        "What is the purpose of the baseline in the layout procedure?",
        "What does the new Iraqi Body Count organization do?",
        "What is the main advantage of the proposed method in terms of computation time?",
        "How many brother does Njoroge have?",
        "Who compiled the 88-page letter to the HHS regarding vaccine safety?",
        "When was Weep Not, Child first published?",
        "What do dendritic spines contain?",
        "How many people attend the 233rd ACS national meeting?",
        "What did Justice Kennedy argue about Quill in Direct Marketing Ass'n v. Brohl?",
        "What factors control the reliance of artificial organisms on plasticity?",
        "What is the problem encountered when building the fuselage sides?",
        "When did Goodwin become a Naval aviator?",
        "对于PD3.0协议，FS312BH支持的最高诱骗电压是多少？",
        "When did Born resign as chairperson of the CFTC?",
        "Which orders did Mufti-e-Azam-e-Hind receive Khilafat from?",
        "What was the reason given by Governor Rick Scott for not implementing a prescription drug monitoring database in Florida?",
        "In which electorate was Simon English elected to the New Zealand Parliament?",
        "When did the 2017 general election be held?",
        "What hedge fund's collapse in 1998 highlighted the need for regulation of derivatives?",
        "What is the dynamical behavior of the anisotropic order parameter following a quench to the critical point?",
        "What is the recommended space for using the VR headset?",
        "What are the three phases of the author's preaching process?",
        "When did KSTP switch to a sports radio format?",
        "What was the best performing model for the Spanish language in Track-1?",
        "According to the text, what is Toby Schindelbeck's observation about the police?",
        "Who is the program chair of this conference?",
        "How does the conduction gap depend on the strain direction?",
        "When was the paper published?",
        "What are the three subsets into which the parameter space V is divided?",
        "What happens to Ngotho after he attacks Jacobo at a workers' strike?",
        "What are some reasons for the lack of data sharing in archaeobotany?",
        "Which air unit did Goodwin command during the initial landings of Marines on Saipan?",
        "How does the receptive field size affect the completion of shapes?",
        "What is the significance of the interlayer Berry connection polarizability?",
        "Can the denoiser be applied to circuits with non-Clifford noise?",
        "What is Professor Tulis's forthcoming book?",
        "How does a media application determine the context of an event?",
        "What are the titles of one of Kam W. Leong's publications in Journal of Controlled Release?",
        "What was the conclusion of the study?",
        "How does the scoring engine generate a stream of content for the channel?",
        "What are the symptoms of vitamin K deficiency?",
        "What is the security parameter for the AES-256 block cipher?",
        "What is the definition of mobile device management (MDM)?",
        "What models were used for dialect identification?",
        "What are the restrictions on the use of Broadjam's servers?",
        "How is the vacuum processing system configured in terms of the arrangement of the vacuum processing apparatus?",
        "What is the average magnetic moment per column in Ge$_{1-x}$Mn$_{x}$ films?",
        "Is there any evidence of heaven and hell?",
        "When will BC leave Boston?",
        "What are the benefits of using binary variables in the SLAS formulation?",
        "Where can users go for troubleshooting and support?",
        "What are the symptoms of alpha thalassemia major?",
        "When did Simon English become the leader of the National Party?",
        "How are smartphones and tablets different from a technical perspective?",
        "What is the sticking point in the political showdown over the budget?",
        "Who is responsible for carrying out the functions assigned under the act?",
        "How does the framework capture the reduced-order dynamics?",
        "How can you level up in the early levels?",
        "What is the electron correlation parameter, $\\Gamma_e$?",
        "How can players skip dialogue on the quest map?",
        "How many years has KSTP-FM 102.1 been on the air?",
        "Besides the Boeing C-17, what other transport aircraft is the IAF considering for acquisition?",
        "What may happen if the VR headset lenses are exposed to sunlight or strong light?",
        "Why does Craig want to find his own place?",
        "What happens to the high resolution of what we focus on at dawn or dusk?",
        "What is the group's request to the Connecticut DEEP Commissioner?",
        "What type of distribution do the tail distributions of price returns follow?",
        "What award did Brooksley Born receive in 2009?",
        "What does the paper aim to solve?",
        "What is the effect of accounting for path preference on the robot's belief update?",
        "What are the two ground states observed for indeno[1,2-a]fluorene on NaCl surfaces?",
        "What is the main focus of the research paper?",
        "What is the rationality coefficient used in the observation model?",
        "Who was Ralph Rokebye's brother?",
        "How are thalassemias classified?",
        "What is the advantage of decorrelating the data before running the PLS algorithm?",
        "What is the name of the generative interactive model used in the method?",
        "What are some potential applications of ferromagnetic semiconductors?",
        "How many underclassmen are on the NBA Draft Early-Entry List?",
        "What is the main topic of the text?",
        "What is the potential of SNNs in modeling the visual system?",
        "What position did Simon English hold in the 2008 general election?",
        "What is the score achieved by the authors for Track-2?",
        "How does the specific-heat ratio affect the average motion of the bubble?",
        "What is the scaling form for the alternative order parameter O?",
        "How are the relationships between catch per set and fishing behavior variables different for different measures of catch per unit effort (CPUE)?",
        "Can someone sell or modify the Agency Spotter Content?",
        "What is the research opportunity that is mentioned?",
        "How is the ground truth for fake news established?",
        "What is the GhostVLAD approach?",
        "By how much does their model outperform the state of the art results?",
        "What additional features and context are proposed?",
        "Which Facebook pages did they look at?",
        "Do the hashtag and SemEval datasets contain only English data?",
        "What type of evaluation is proposed for this task?",
        "What are the datasets used for evaluation?",
        "How does this approach compare to other WSD approaches employing word embeddings?",
        "How does their ensemble method work?",
        "What are the sources of the datasets?",
        "what language does this paper focus on?",
        "What sentiment analysis dataset is used?",
        "What accuracy does the proposed system achieve?",
        "Did they experiment with this new dataset?",
        "What datasets are used?",
        "Which stock market sector achieved the best performance?",
        "what NMT models did they compare with?",
        "What are the three regularization terms?",
        "What are the baselines?",
        "By how much did they improve?",
        "How does their model improve interpretability compared to softmax transformers?",
        "what was the baseline?",
        "What metrics are used for evaluation?",
        "What is the attention module pretrained on?",
        "What kind of stylistic features are obtained?",
        "What architecture does the encoder have?",
        "Is WordNet useful for taxonomic reasoning for this task?",
        "what were the baselines?",
        "How many users do they look at?",
        "What metrics are used for evaluation?",
        "What labels do they create on their dataset?",
        "How much data is needed to train the task-specific encoder?",
        "What tasks are used for evaluation?",
        "What is the improvement in performance for Estonian in the NER task?",
        "What background do they have?",
        "LDA is an unsupervised method; is this paper introducing an unsupervised approach to spam detection?",
        "Which languages are similar to each other?",
        "which lstm models did they compare with?",
        "How large is their data set?",
        "How were the human judgements assembled?",
        "Do they test their framework performance on commonly used language pairs, such as English-to-German?",
        "How are models evaluated in this human-machine communication game?",
        "What evaluation metrics are looked at for classification tasks?",
        "What are the source and target domains?",
        "what previous RNN models do they compare with?",
        "What neural network modules are included in NeuronBlocks?",
        "what datasets did they use?",
        "What were the baselines?",
        "What are the languages they use in their experiment?",
        "What other tasks do they test their method on?",
        "Do they use pretrained embeddings?",
        "Was PolyReponse evaluated against some baseline?",
        "How do they obtain psychological dimensions of people?",
        "What argument components do the ML methods aim to identify?",
        "Ngrams of which length are aligned using PARENT?",
        "How large is the Twitter dataset?",
        "What are the 12 languages covered?",
        "What are two datasets model is applied to?",
        "Were any of the pipeline components based on deep learning models?",
        "How is the quality of the data empirically evaluated? ",
        "How do they combine audio and text sequences in their RNN?",
        "by how much did their model improve?",
        "how many humans evaluated the results?",
        "What is their definition of tweets going viral?",
        "Which basic neural architecture perform best by itself?",
        "what is the source of the data?",
        "What machine learning and deep learning methods are used for RQE?",
        "What is the benchmark dataset and is its quality high?",
        "What architecture does the decoder have?",
        "Do they report results only on English data?",
        "What is best performing model among author's submissions, what performance it had?",
        "what was the baseline?",
        "What was their highest recall score?",
        "What embedding techniques are explored in the paper?",
        "How do they match words before reordering them?",
        "Does the paper explore extraction from electronic health records?",
        "Who were the experts used for annotation?",
        "What models are used for painting embedding and what for language style transfer?",
        "On top of BERT does the RNN layer work better or the transformer layer?",
        "Do the authors hypothesize that humans' robustness to noise is due to their general knowledge?",
        "What cyberbulling topics did they address?",
        "How do they obtain the new context represetation?",
        "How many different types of entities exist in the dataset?",
        "How much higher quality is the resulting annotated data?",
        "How big is imbalance in analyzed corpora?",
        "What dataset does this approach achieve state of the art results on?",
        "What are strong baselines model is compared to?",
        "What type of classifiers are used?",
        "Which toolkits do they use?",
        "On what datasets are experiments performed?",
        "what are the existing approaches?",
        "Do they use attention?",
        "What datasets did they use for evaluation?",
        "What sentiment classification dataset is used?",
        "Were any of these tasks evaluated in any previous work?",
        "Is datasets for sentiment analysis balanced?",
        "What is the invertibility condition?",
        "How does proposed qualitative annotation schema looks like?",
        "what are the sizes of both datasets?",
        "What are the baselines?",
        "Which natural language(s) are studied in this paper?",
        "What models are used in the experiment?",
        "Do the answered questions measure for the usefulness of the answer?",
        "what pretrained word embeddings were used?",
        "What were their results on the new dataset?",
        "What is the combination of rewards for reinforcement learning?",
        "What limitations do the authors demnostrate of their model?",
        "Which existing benchmarks did they compare to?",
        "What were their distribution results?",
        "How is the dataset of hashtags sourced?",
        "what accents are present in the corpus?",
        "What can word subspace represent?",
        "What baseline model is used?",
        "Is SemCor3.0 reflective of English language data in general?",
        "How big is Augmented LibriSpeech dataset?",
        "What dataset did they use?",
        "Do they use large or small BERT?",
        "Are the automatically constructed datasets subject to quality control?",
        "Are the images from a specific domain?",
        "What was their performance on emotion detection?",
        "What is the tagging scheme employed?",
        "Is Arabic one of the 11 languages in CoVost?",
        "How do they define robustness of a model?",
        "What other sentence embeddings methods are evaluated?",
        "What are method's improvements of F1 for NER task for English and Chinese datasets?",
        "On which tasks do they test their conflict method?",
        "Which baselines did they compare against?",
        "What is te core component for KBQA?",
        "What are the baseline models?",
        "Which methods are considered to find examples of biases and unwarranted inferences??",
        "What language do they explore?",
        "Which models did they experiment with?",
        "Do they report results only on English data?",
        "What summarization algorithms did the authors experiment with?",
        "What was the previous state of the art for this task?",
        "Which component is the least impactful?",
        "What is the corpus used for the task?",
        "Which 7 Indian languages do they experiment with?",
        "What is the model performance on target language reading comprehension?",
        "How big is the difference in performance between proposed model and baselines?",
        "How much improvement is gained from Adversarial Reward Augmented Maximum Likelihood (ARAML)?",
        "What evidence do the authors present that the model can capture some biases in data annotation and collection?",
        "Were other baselines tested to compare with the neural baseline?",
        "What is the size of the dataset?",
        "What are method improvements of F1 for paraphrase identification?",
        "What datasets are used?",
        "What data was presented to the subjects to elicit event-related responses?",
        "Which baselines are used for evaluation?",
        "What learning models are used on the dataset?",
        "What language model architectures are used?",
        "How are weights dynamically adjusted?",
        "What are the results from these proposed strategies?",
        "What does an individual model consist of?",
        "How is non-standard pronunciation identified?",
        "What is a semicharacter architecture?",
        "which languages are explored?",
        "How effective is their NCEL approach overall?",
        "Is the data de-identified?",
        "What was the baseline used?",
        "where did they obtain the annotated clinical notes from?",
        "Why masking words in the decoder is helpful?",
        "Which dataset do they use?",
        "What features are used?",
        "How is the dataset annotated?",
        "Which eight NER tasks did they evaluate on?",
        "How was the training data translated?",
        "What model did they use for their system?",
        "What was the baseline for this task?",
        "What baselines do they compare with?",
        "How is the political bias of different sources included in the model?",
        "Where does the ancient Chinese dataset come from?",
        "In what language are the tweets?",
        "which chinese datasets were used?",
        "How many layers does the UTCNN model have?",
        "what dataset is used in this paper?",
        "What are the clinical datasets used in the paper?",
        "What traditional linguistics features did they use?",
        "What metrics are used to establish that this makes chatbots more knowledgeable and better at learning and conversation? ",
        "Do they employ their indexing-based method to create a sample of a QA Wikipedia dataset?",
        "Which sports clubs are the targets?",
        "What experiments are conducted?",
        "How does Gaussian-masked directional multi-head attention works?",
        "What types of social media did they consider?",
        "What are the network's baseline features?",
        "Which hyperparameters were varied in the experiments on the four tasks?",
        "What were the scores of their system?",
        "How large is the corpus?",
        "Is it possible to convert a cloze-style questions to a naturally-looking questions?",
        "What NLP tasks do they consider?",
        "What previous methods is their model compared to?",
        "How larger are the training sets of these versions of ELMo compared to the previous ones?",
        "How many sentences does the dataset contain?",
        "Which models/frameworks do they compare to?",
        "Does their NER model learn NER from both text and images?",
        "Do they evaluate only on English datasets?",
        "What was their highest MRR score?",
        "What datasets do they evaluate on?",
        "How do the authors evidence the claim that many engineers find it a big overhead to choose from multiple frameworks, models and optimization techniques?",
        "On which benchmarks they achieve the state of the art?"
    ],
    "answer": [
        "No, it is not necessary.",
        "Low temperature scanning tunneling microscopy and spectroscopy (STM/STS).",
        "Implantable Cardioverter Defibrillator (ICD) is a surgically implanted electronic device to treat life-threatening heartbeat irregularities.",
        "The sides of the fuselage are sloped to create a conical section when the fuselage is formed.",
        "Electricity is used for transport, heating, lighting, communications, and computation.",
        "Vice Admiral.",
        "Vitamins K3, K4, and K5.",
        "Yes, individual molecules of indeno[1,2-a]fluorene can switch between open-shell and closed-shell states by changing their adsorption site on the surface.",
        "3-D printing and software development.",
        "90 μg for women and 120 μg for men.",
        "Watt, one joule per second.",
        "Flexibility.",
        "Jacob C. Landau.",
        "An unsupervised method based on the information bottleneck and contrastive learning.",
        "Using the vacuum Einstein equation and the Baez-Bunn form.",
        "The water depth in the Greater Ekofisk Area is 70-75 meters.",
        "Other toxic products.",
        "L = 8 and L = 14.",
        "5.",
        "Lasa, Gitastrophe, and Shadoks.",
        "It required the transformation to be limited to specific data and a visual depiction representing specific objects or substances.",
        "As the transition probability increases, the learning rate initially rises and then declines.",
        "A subset that form via kinetic rate processes from state-selected Rydberg gases.",
        "Wearable sensors.",
        "\"I have seen the Lord.\".",
        "Verifying other meta-information such as patient's gender, age, race, etc.",
        "The baseline is used as a reference for the mid point of the firewall for the developed side panel.",
        "It provides cover for the war and allows supporters of the illegal war to point to it.",
        "The time required to update the belief does not increase with the complexity of the environment.",
        "Four.",
        "Del Bigtree and his team at ICAN.",
        "Weep Not, Child was first published in 1964.",
        "They are rich in actin and have been shown to be highly dynamic.",
        "There are 14,520 attendees, including 7,152 chemical scientists, 5,059 students, 1,283 exhibitors, 119 precollege teachers, 573 exposition visitors, and 453 guests.",
        "Quill harmed states more than anticipated due to the Internet.",
        "Environmental fluctuation and uncertainty control the reliance of artificial organisms on plasticity.",
        "The longerons bow up from the building surface, forming a \"banana\" shape.",
        "Goodwin became a Naval aviator in January 1929.",
        "48V.",
        "June 1, 1999.",
        "Mufti-e-Azam-e-Hind received Khilafat in the Qaderi, Chishti, Nakshbandi, Suharwardi, and Madaari Orders.",
        "Privacy concerns and skepticism about its effectiveness.",
        "The Wallace electorate.",
        "23 September.",
        "Long Term Capital Management (LTCM).",
        "It is well described by the Gaussian theory.",
        "It is recommended to have at least a 2x2 meter space for using the VR headset.",
        "The three phases are exegetical, theological, and homiletical.",
        "KSTP switched to a sports radio format on February 15, 2010.",
        "The best performing model for the Spanish language in Track-1 was Spanish BERT.",
        "Toby Schindelbeck's observation is that the police say they aren't paid enough to enforce the laws in the streets.",
        "Peter Denning.",
        "Peaks occur at certain strain directions, while the gap is zero at others.",
        "The paper was published on 7 March 2023.",
        "The three subsets are V+, V0, and V-, determined by the Kullback-Leibler information distance.",
        "After attacking Jacobo at a workers' strike, Ngotho loses his job and Njoroge's family is forced to move.",
        "Technological limitations, resistance to exposing data to scrutiny, and desire to hold onto data for personal use.",
        "VC-10 Squadron.",
        "Bigger receptive field size leads to more successful shape completion.",
        "The momentum space curl of the interlayer Berry connection polarizability generates the crossed nonlinear dynamical Hall effect.",
        "Yes, the denoiser works for non-Clifford local noise channels.",
        "Legacies of Losing in American Politics and an expanded edition of The Rhetorical Presidency in the Princeton Classics series.",
        "It uses a content-recognition module or algorithm.",
        "Sustained viral gene delivery through core-shell fibers and Gene transfer to hemophilia A mice via oral delivery of FVIII-chitosan nanoparticles.",
        "The conclusion was that fruit consumption may provide a protective effect for mercury exposure in Amazonian riparians.",
        "By comparing candidate content items to a model and scoring them.",
        "Symptoms of vitamin K deficiency include anemia, bruising, nosebleeds, bleeding of the gums, and heavy menstrual bleeding in women.",
        "172.",
        "Centralized control of mobile devices and applications.",
        "BERT, RoBERTa, ELECTRA, GPT-2, and XLM-RoBERTa.",
        "No excessive overloading and no use for illegal activity.",
        "Multiple vacuum processing apparatuses are arranged in parallel.",
        "1425 $\\mu_{B}$.",
        "Unknown.",
        "August 25.",
        "Reduced computational complexity.",
        "Online documentation, QuecPython community, online support: QQ group 445121768.",
        "Severe anemia that begins even before birth.",
        "October 2001.",
        "Smartphones are more compact and power constrained.",
        "The sticking point in the political showdown over the budget is how much spending to cut.",
        "The Director of Town and Country Planning is responsible for carrying out the functions assigned under the act.",
        "By using a propagator in the latent space.",
        "Keep deploying and harvesting your bases to earn experience points and level up quickly.",
        "It is the ratio of the average unscreened electron-electron potential energy to kinetic energy.",
        "Players can skip dialogue on the quest map by pressing the 'SKIP' button.",
        "Four years.",
        "The IAF is considering the acquisition of the Airbus A330 MRTT (Multi-Role Tanker Transport) besides the Boeing C-17.",
        "Exposure to sunlight or strong light may cause permanent yellow spot damage on the screen.",
        "Because his roommate smokes.",
        "It becomes a bit less so that what's off to the left or right can be better noted.",
        "Appointing a blue ribbon commission to conduct the research and develop the management plan and denying or defering approval on any applications for new docks in the Cove until the management plan can be developed and implemented.",
        "Power-law functions.",
        "In 2009, Brooksley Born received the John F. Kennedy Profiles in Courage Award.",
        "The paper aims to solve nonlinear system vibration problems efficiently.",
        "The belief entropy decreases more steadily.",
        "Open-shell π-diradical state and closed-shell state with a para-quinodimethane moiety.",
        "Nuclear liquid-gas transition in lattice QCD.",
        "γh.",
        "Sir Richard.",
        "According to the globin that is affected (alpha or beta).",
        "Decorrelating the data before running the PLS algorithm improves the performance of the algorithm.",
        "The generative interactive model used in the method is called the Coupled Generalized Dynamic Bayesian Network (C-GDBN).",
        "Spin injection into non magnetic semiconductors, or electrical manipulation of carrier induced magnetism in magnetic semiconductors.",
        "62.",
        "The main topic of the text is Iraq's politics and current situation.",
        "SNNs have the potential to better model and explain the functional hierarchy and mechanisms of the visual system.",
        "He became deputy prime minister and minister of finance.",
        "85.61%.",
        "The specific-heat ratio affects the average motion of the bubble. The bubbles with smaller specific-heat ratios have slower average motion.",
        "O(t, L_{\\parallel}; S_\\Delta) = L_{\\parallel}^{-\\beta/[\\nu(1+\\Delta)]} \\tilde f_O(t/L_{\\parallel}^{z/(1+\\Delta)}; S_\\Delta).",
        "The relationships between catch per set and fishing behavior variables differ when comparing unstandardized CPUE and standardized CPUE.",
        "No.",
        "A study on the effects of Brazilian Jiu Jitsu and psychotherapy on people with autism.",
        "Ground truth is not established in the paper",
        "extension of the NetVLAD, adds Ghost clusters along with the NetVLAD clustersAn extension of NetVLAD which replaces hard assignment-based clustering with soft assignment-based clustering with the additon o fusing Ghost clusters to deal with noisy content.",
        "the attention model, MDREA, also outperforms the best existing research results (WAP 0.690 to 0.688)",
        "using tweets that one has replied or quoted to as contextual informationtext sequences of context tweets",
        "FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, DisneyFoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney.",
        "YesYes",
        "Answer with content missing: (Evaluation Metrics section) Precision, Recall, F1-scores, Strict match, METEOR, ROUGE-2",
        "CNN/DailyMail news highlights, New York Times Annotated Corpus, XSumthe CNN/DailyMail news highlights dataset BIBREF24, the New York Times Annotated Corpus (NYT; BIBREF25), XSum BIBREF22",
        "GM$\\_$KL achieves better correlation than existing approaches for various metrics on SCWS dataset.",
        "simply averaging the predictions from the constituent single models",
        "Friends TV sitcom, Facebook messenger chats",
        "EnglishSimple English",
        "IMDb dataset of movie reviewsIMDb",
        "F1 scores of 85.99 on the DL-PS data,  75.15 on the EC-MT data and 71.53 on the EC-UQ data F1 of 85.99 on the DL-PS dataset (dialog domain); 75.15 on EC-MT and 71.53 on EC-UQ (e-commerce domain)",
        "No",
        "Custom dataset with user questions; set of documents, twitter posts and news articles, all related to finance.a self-collected financial intents dataset in Portuguese",
        "Energy with accuracy of 0.538Energy",
        "RNN-based NMT model, Transformer-NMT",
        "a regularization term associated with neutral features, the maximum entropy of class distribution regularization term, the KL divergence between reference and predicted class distributiona regularization term associated with neutral features,  the maximum entropy of class distribution, KL divergence between reference and predicted class distribution",
        "SVM with unigram, bigram, and trigram features, SVM with average word embedding, SVM with average transformed word embeddings, CNN, ecurrent Convolutional Neural Networks, SVM and deep learning models with comment informationSVM with unigram, bigram, trigram features, with average word embedding, with average transformed word embeddings, CNN and RCNN, SVM, CNN, RCNN with comment information",
        "They decrease MAE in 0.34",
        "the attention heads in the proposed adaptively sparse Transformer can specialize more and with higher confidenceWe introduce sparse attention into the Transformer architecture",
        " MT system on the data released by BIBREF11Transformer base, two-pass CADec model",
        "translation probabilities, Labeled Attachment Scores (LAS)accuracy, Labeled Attachment Scores (LAS)",
        "the model is pre-trained on CTC-based ASR task and MT task in the pre-training stage.",
        "Unanswerable",
        "LSTMLSTM",
        "UnanswerableYes",
        "UnanswerableLF-MMI Attention\nSeq2Seq \nRNN-T \nChar E2E LF-MMI \nPhone E2E LF-MMI \nCTC + Gram-CTC",
        "22,880 users20,000",
        "Byte-Pair Encoding perplexity  (BPE PPL),\nBLEU-1,\nBLEU-4,\nROUGE-L,\npercentage of distinct unigram (D-1),\npercentage of distinct bigrams(D-2),\nuser matching accuracy(UMA),\nMean Reciprocal Rank(MRR)\nPairwise preference over baseline(PP)BLEU-1/4 and ROUGE-L, likelihood of generated recipes using identical input specifications but conditioned on ten different user profiles, user matching accuracy (UMA), Mean Reciprocal Rank (MRR), neural scoring model from BIBREF33 to measure recipe-level coherence Distinct-1/2, UMA = User Matching Accuracy, MRR\n= Mean Reciprocal Rank, PP = Pairwise preference over baseline (evaluated for 310 recipe pairs per model)",
        "(1) the time the patient has been experiencing the symptom, (2) activities that trigger the symptom (to occur or worsen), (3) the extent of seriousness, (4) the frequency occurrence of the symptom, and (5) the location of symptom, No Answerthe time the patient has been experiencing the symptom, activities that trigger the symptom, the extent of seriousness, the frequency occurrence of the symptom, the location of symptom, 9 symptoms",
        "57,505 sentences57,505 sentences",
        "four machine translation tasks: German -> English, Japanese -> English, Romanian -> English, English -> German four machine translation tasks, IWSLT 2017 German $\\rightarrow $ English BIBREF27, KFTT Japanese $\\rightarrow $ English BIBREF28, WMT 2016 Romanian $\\rightarrow $ English BIBREF29, WMT 2014 English $\\rightarrow $ German BIBREF30",
        "5 percent points.0.05 F1",
        "Unanswerable",
        "NoNo",
        "Nguni languages (zul, xho, nbl, ssw), Sotho languages (nso, sot, tsn)The Nguni languages are similar to each other, The same is true of the Sotho languages",
        "Unidirectional LSTM networks with 2, 6, 7, 8, and  9 layers.",
        "a sample of  29,794 wikipedia articles and 2,794 arXiv papers ",
        "50 human annotators ranked a random sample of 100 translations by Adequacy, Fluency and overall ranking on a 5-point scale.adequacy, precision and ranking values",
        "YesYes",
        "by training an autocomplete system on 500K randomly sampled sentences from Yelp reviewsefficiency of a communication scheme $(q_{\\alpha },p_{\\beta })$ by the retention rate of tokens, which is measured as the fraction of tokens that are kept in the keywords, accuracy of a scheme is measured as the fraction of sentences generated by greedily decoding the model that exactly matches the target sentence",
        "Precision, Recall, F-measure, accuracyPrecision, Recall and F-measure",
        "Book, electronics, beauty, music, IMDB, Yelp, cell phone, baby, DVDs, kitchenwe use set 1 of the source domain as the only source with sentiment label information during training, and we evaluate the trained model on set 1 of the target domain, Book (BK), Electronics (E), Beauty (BT), and Music (M)",
        "Variational LSTM, CharCNN, Pointer Sentinel-LSTM, RHN, NAS Cell, SRU, QRNN, RAN, 4-layer skip-connection LSTM, AWD-LSTM, Quantized LSTM",
        "Embedding Layer, Neural Network Layers, Loss Function, MetricsEmbedding Layer, Neural Network Layers, Loss Function, Metrics",
        "the Carnegie Mellon Pronouncing Dictionary BIBREF12, the multilingual pronunciation corpus collected by deri2016grapheme , ranscriptions extracted from Wiktionarymultilingual pronunciation corpus collected by deri2016grapheme",
        "varied from Maximum Entropy Classifiers (BIBREF4) to Support Vector Machines (BIBREF5,BIBREF6,BIBREF7,BIBREF8), Recursive Neural Networks (BIBREF9,BIBREF10), Convolutional Neural Networks (BIBREF11) and most recently transfer learning-based architectures like Bidirectional Encoder Representation from Transformers (BERT) (BIBREF12)",
        "English\nFrench\nSpanish\nGerman\nGreek\nBulgarian\nRussian\nTurkish\nArabic\nVietnamese\nThai\nChinese\nHindi\nSwahili\nUrdu\nFinnishEnglish, Spanish, Finnish",
        "None",
        "YesYes",
        "NoNo",
        "using the Meaning Extraction MethodUnanswerable",
        "claim, premise, backing, rebuttal, and refutationclaim, premise, backing, rebuttal, refutation",
        "UnanswerableAnswer with content missing: (Parent subsections) combine precisions for n-gram orders 1-4",
        "1,873 Twitter conversation threads, roughly 14k tweets1,873 Twitter conversation threads, roughly 14k tweets",
        "Chinese Mandarin, Welsh, English, Estonian, Finnish, French, Hebrew, Polish, Russian, Spanish, Kiswahili, Yue ChineseChinese Mandarin, Welsh, English, Estonian, Finnish, French, Hebrew, Polish, Russian, Spanish, Kiswahili, Yue Chinese",
        " `Conversations Gone Awry' dataset, subreddit ChangeMyViewAn expanded version of the existing 'Conversations Gone Awry' dataset and the ChangeMyView dataset, a subreddit whose only annotation is whether the conversation required action by the Reddit moderators. ",
        "NoNo",
        "Validated transcripts were sent to professional translators., various sanity checks to the translations,  sanity check the overlaps of train, development and test setscomputed sentence-level BLEU, We manually inspected examples where the source transcript was identical to the translation, measured the perplexity of the translations, computed the ratio of English characters in the translations, calculate similarity scores between transcripts and translations",
        "combines the information from these sources using a feed-forward neural modelencodes the information from audio and text sequences using dual RNNs and then combines the information from these sources using a feed-forward neural model",
        "For the WikiLarge dataset, the improvement over baseline NMT is 2.11 BLEU, 1.7 FKGL and 1.07 SARI.\nFor the WikiSmall dataset, the improvement over baseline NMT is  8.37 BLEU.6.37 BLEU",
        "UnanswerableUnanswerable",
        "Viral tweets are the ones that are retweeted more than 1000 timesthose that contain a high number of retweets",
        "BERT",
        "Android application",
        "Logistic Regression, neural networks",
        "Social Honeypot dataset (public) and Weibo dataset (self-collected); yesSocial Honeypot, which is not of high quality",
        "LSTMLSTM",
        "UnanswerableUnanswerable",
        "For SLC task, the \"ltuorp\" team  has the best performing  model (0.6323/0.6028/0.6649 for F1/P/R  respectively) and for FLC task the \"newspeak\" team  has the best performing  model (0.2488/0.2863/0.2201 for F1/P/R respectively).",
        "pivot-based translation relying on a helping language BIBREF10, nduction of phrase tables from monolingual data BIBREF14 , attentional RNN-based model (RNMT) BIBREF2, Transformer model BIBREF18, bi-directional model BIBREF11, multi-to-multi (M2M) model BIBREF8, back-translation BIBREF17M2M Transformer",
        "0.70330.7033",
        "Skip–gram, CBOWintegrated vector-res, vector-faith, Skip–gram, CBOW",
        "UnanswerableCFILT-preorder system",
        "Yes",
        "Individuals with legal trainingYes",
        "generating a poem from images we use an existing actor-critic architecture, various types of sequence to sequence models",
        "Transformer over BERT (ToBERT)The transformer layer",
        "YesYes",
        "personal attack, racism, and sexismracism, sexism, personal attack, not specifically about any single topic",
        "They use two independent convolutional and max-pooling layers on (1) a combination of the left context, the left entity and the middle context; and (2) a combination of the middle context, the right entity and the right context. They concatenated the two results after pooling to get the new context representation.",
        "OurNepali contains 3 different types of entities, ILPRL contains 4 different types of entitiesthree",
        "improvement when the difficult subset with expert annotations is mixed with the remaining crowd annotation is 3.5 F1 score, much larger than when a random set of expert annotations are added",
        "Women represent 33.16% of the speakers",
        "the English-German dataset",
        "Baseline models are:\n- Chen et al., 2015a\n- Chen et al., 2015b\n- Liu et al., 2016\n- Cai and Zhao, 2016\n- Cai et al., 2017\n- Zhou et al., 2017\n- Ma et al., 2018\n- Wang et al., 2019",
        "probabilistic modelLogistic Regression, Multilayer Perceptron",
        "BIBREF17, BIBREF18, TensiStrength BIBREF13, TwitterNLP BIBREF6, BIBREF19, CogComp-NLP BIBREF20, Stanford NLP NER BIBREF21BIBREF23, BIBREF17, BIBREF18, BIBREF19, BIBREF24, BIBREF25, BIBREF26",
        "SQuADSQuAD",
        "BOW-Tags, BOW-KL(Tags), BOW-All, GloVe",
        "YesYes",
        "CSAT dataset, 20 newsgroups, Fisher Phase 1 corpusCSAT dataset , 20 newsgroups, Fisher Phase 1 corpus",
        "the IMDb movie review dataset BIBREF17IMDb movie review",
        "YesYes",
        "No",
        "The neural projector must be invertible.we constrain our neural projector with two requirements: (1) INLINEFORM0 and (2) INLINEFORM1 exists",
        "The resulting taxonomy of the framework is shown in Figure FIGREF10FIGREF10",
        "training set has 89,042 sentence pairs, and the test set has 100 pairs, training set contains 296,402, 2,000 for development and 359 for testingWikiSmall  89 142 sentence pair and  WikiLarge 298 761 sentence pairs. ",
        "Vanilla ST baseline, encoder pre-training, in which the ST encoder is initialized from an ASR model, decoder pre-training, in which the ST decoder is initialized from an MT model, encoder-decoder pre-training, where both the encoder and decoder are pre-trained, many-to-many multi-task model where the encoders and decoders are derived from pre-trained ASR and MT models, Triangle+pre-train: BIBREF18 DBLP:conf/naacl/AnastasopoulosC18 proposed a triangle multi-task strategy for speech translationVanilla ST baseline, Pre-training baselines, Multi-task baselines, Many-to-many+pre-training, Triangle+pre-trainVanilla ST baseline: The vanilla ST BIBREF9 has only a speech encoder and a decoder. It is trained from scratch on the ST-TED corpus.\n\nPre-training baselines: We conduct three pre-training baseline experiments: 1) encoder pre-training, in which the ST encoder is initialized from an ASR model; 2) decoder pre-training, in which the ST decoder is initialized from an MT model; and 3) encoder-decoder pre-training, where both the encoder and decoder are pre-trained. The ASR model has the same architecture with vanilla ST model, trained on the mixture of ST-TED and TED-LIUM2 corpus. The MT model has a text encoder and decoder with the same architecture of which in TCEN. It is first trained on WMT data (out-of-domain) and then fine-tuned on in-domain data.\n\nMulti-task baselines: We also conduct three multi-task baseline experiments including one-to-many setting, many-to-one setting, and many-to-many setting. In the first two settings, we train the model with $\\alpha _{st}=0.75$ while $\\alpha _{asr}=0.25$ or $\\alpha _{mt}=0.25$. For many-to-many setting, we use $\\alpha _{st}=0.6, \\alpha _{asr}=0.2$ and $\\alpha _{mt}=0.2$.. For MT task, we use only in-domain data.\n\nMany-to-many+pre-training: We train a many-to-many multi-task model where the encoders and decoders are derived from pre-trained ASR and MT models. ",
        "UnanswerableEnglish",
        "linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)linear SVM trained on word unigrams,  bidirectional Long Short-Term-Memory (BiLSTM),  Convolutional Neural Network (CNN) ",
        "No",
        "Pretrained word embeddings  were not usedGloVe, Edinburgh embeddings BIBREF14, Emoji embeddings BIBREF16",
        "average recipe-level coherence scores of 1.78-1.82, human evaluators preferred personalized model outputs to baseline 63% of the time",
        "irony accuracy, sentiment preservation irony accuracy and sentiment preservation",
        "Since we do not have an end-to-end dataset, the generated English poem may not work well with Shakespeare style transferwe do not have an end-to-end dataset, the generated English poem may not work well with Shakespeare style transfer as shown in Figure FIGREF12 for \"Starry Night\" with a low average content score",
        "Affective Text, Fairy Tales, ISEAR Affective Text dataset, Fairy Tales dataset, ISEAR dataset",
        "Distributions of Followers, Friends and URLs are significantly different between the set of tweets containing fake news and those non containing them, but for Favourites, Mentions, Media, Retweets and Hashtags they are not significantly different",
        "1,268 randomly selected tweets in the Stanford Sentiment Analysis Dataset BIBREF36, all 12,594 unique English hashtags and their associated tweets from the same Stanford datasetStanford Sentiment Analysis Dataset BIBREF36",
        "UnanswerableUnanswerable",
        "Word vectors, usually in the context of others within the same class",
        "For Article-Entity placement, they consider two baselines: the first one using only salience-based features, and the second baseline checks if the entity appears in the title of the article. \n\nFor Article-Section Placement, they consider two baselines: the first picks the section with the highest lexical similarity to the article, and the second one picks the most frequent section.B1. The first baseline uses only the salience-based features by Dunietz and Gillick BIBREF11 ., B2. The second baseline assigns the value relevant to a pair INLINEFORM0 , if and only if INLINEFORM1 appears in the title of INLINEFORM2 .\n\n, S1: Pick the section from template INLINEFORM0 with the highest lexical similarity to INLINEFORM1 : S1 INLINEFORM2, S2: Place the news into the most frequent section in INLINEFORM0",
        "YesUnanswerable",
        "UnanswerableUnanswerable",
        " high-quality datasets  from SemEval-2016 “Sentiment Analysis in Twitter” task SemEval-2016 “Sentiment Analysis in Twitter”",
        "small BERTsmall BERT",
        "NoNo",
        "YesYes",
        "Answer with content missing: (Table 3) Best author's model B-M average micro f-score is 0.409, 0.459, 0.411 on Affective, Fairy Tales and ISEAR datasets respectively. ",
        "A new tagging scheme that tags the words before and after the pun as well as the pun words.a new tagging scheme consisting of three tags, namely { INLINEFORM0 }",
        "NoNo",
        "ability to accurately classify texts even when the amount of prior knowledge for different classes is unbalanced, and when the class distribution of the dataset is unbalancedLow sensitivity to bias in prior knowledge",
        "GloVe, BERT, Universal Sentence Encoder, TF-IDF, InferSentAvg. GloVe embeddings, Avg. fast-text embeddings, Avg. BERT embeddings, BERT CLS-vector, InferSent - GloVe and Universal Sentence Encoder.",
        "English datasets including CoNLL2003 and OntoNotes5.0, our proposed method outperforms BERT-MRCBIBREF38 by +0.29 and +0.96 respectively, Chinese datasets, achieving F1 improvements by +0.97 and +2.36 on MSRA and OntoNotes4.0, respectivelyFor English datasets including CoNLL2003 and OntoNotes5.0, our proposed method outperforms BERT-MRCBIBREF38 by +0.29 and +0.96 respectively., huge performance boosts on Chinese datasets, achieving F1 improvements by +0.97 and +2.36 on MSRA and OntoNotes4.0, respectively",
        "Task 1: Quora Duplicate Question Pair Detection, Task 2: Ranking questionsQuora Duplicate Question Pair Detection, Ranking questions in Bing's People Also Ask",
        "Various tree structured neural networks including variants of Tree-LSTM, Tree-based CNN, RNTN, and non-tree models including variants of LSTMs, CNNs, residual, and self-attention based networksSentence classification baselines: RNTN (Socher et al. 2013), AdaMC-RNTN (Dong et al. 2014), TE-RNTN (Qian et al. 2015), TBCNN (Mou et al. 2015), Tree-LSTM (Tai, Socher, and Manning 2015), AdaHT-LSTM-CM (Liu, Qiu, and Huang 2017), DC-TreeLSTM (Liu, Qiu, and Huang 2017), TE-LSTM (Huang, Qian, and Zhu 2017), BiConTree (Teng and Zhang 2017), Gumbel Tree-LSTM (Choi, Yoo, and Lee 2018), TreeNet (Cheng et al. 2018), CNN (Kim 2014), AdaSent (Zhao, Lu, and Poupart 2015), LSTM-CNN (Zhou et al. 2016), byte-mLSTM (Radford, Jozefowicz, and Sutskever 2017), BCN + Char + CoVe (McCann et al. 2017), BCN + Char + ELMo (Peters et al. 2018). \nStanford Natural Language Inference baselines: Latent Syntax Tree-LSTM (Yogatama et al. 2017), Tree-based CNN (Mou et al. 2016), Gumbel Tree-LSTM (Choi, Yoo, and Lee 2018), NSE (Munkhdalai and Yu 2017), Reinforced Self- Attention Network (Shen et al. 2018), Residual stacked encoders: (Nie and Bansal 2017), BiLSTM with generalized pooling (Chen, Ling, and Zhu 2018).",
        "answer questions by obtaining information from KB tuples hierarchical matching between questions and relations with residual learning",
        "name-based Nearest-Neighbor model (NN), Encoder-Decoder baseline with ingredient attention (Enc-Dec)",
        "spot patterns by just looking at a collection of images, tag all descriptions with part-of-speech information, I applied Louvain clusteringLooking for adjectives marking the noun \"baby\" and also looking for most-common adjectives related to certain nouns using POS-tagging",
        "English, French, German French, English, Spanish, Italian, Portuguese, Hebrew, Arabic",
        "Stacked LSTMs, Cell-aware Stacked LSTMs, Sentence Encoders, Top-layer Classifiers",
        "YesUnanswerable",
        "LSA, TextRank, LexRank and ILP-based summary.LSA, TextRank, LexRank",
        "hLSTMhLSTM",
        "Based on table results provided changing directed to undirected edges had least impact - max abs difference of 0.33 points on all three datasets.",
        "DTA18, DTA19Diachronic Usage Relatedness (DURel) gold standard data set",
        "Hindi, English, Kannada, Telugu, Assamese, Bengali and MalayalamKannada, Hindi, Telugu, Malayalam, Bengali,  English and Assamese (in table, missing in text)",
        "Table TABREF6, Table TABREF8when testing on English, the F1 score of the model training on Chinese (Zh) is 53.8,  F1 score is only 44.1 for the model training on Zh-En",
        "Metric difference between Aloha and best baseline score:\nHits@1/20: +0.061 (0.3642 vs 0.3032)\nMRR: +0.0572(0.5114 vs 0.4542)\nF1: -0.0484 (0.3901 vs 0.4385)\nBLEU: +0.0474 (0.2867 vs 0.2393)",
        "ARAM has achieved improvement over all baseline methods using reverese perplexity and  slef-BLEU metric.  The maximum reverse perplexity improvement 936,16 is gained for EMNLP2017  WMT  dataset and  48,44 for COCO dataset.Compared to the baselines, ARAML does not do better in terms of perplexity on COCO and EMNLP 2017 WMT datasets, but it does by up to 0.27 Self-BLEU points on COCO and 0.35 Self-BLEU on EMNLP 2017 WMT. In terms of Grammaticality and Relevance, it scores better than the baselines on up to 75.5% and 73% of the cases respectively.",
        "The authors showed few tweets where neither and implicit hatred content exist but the model was able to discriminate",
        "SVM, No-Answer Baseline (NA) , Word Count Baseline, Human PerformanceNo-Answer Baseline (NA), Word Count Baseline, Human Performance",
        "Dataset contains 3606 total sentences and 79087 total entities.ILPRL contains 548 sentences, OurNepali contains 3606 sentences",
        "Using DSC loss improves the F1 score by +0.58 for MRPC and +0.73 for QQP+0.58",
        "Answer with content missing: (Whole Method and Results sections) The primary dataset we use is the ERP data collected and computed by Frank et al. (2015), and we also use behavioral data (eye-tracking data and self-paced reading times) from Frank et al. (2013) which were collected on the same set of 205 sentences.\nSelect:\n- ERP data collected and computed by Frank et al. (2015)\n- behavioral data (eye-tracking data and self-paced reading times) from Frank et al. (2013)the ERP data: BIBREF0",
        "7 phonemic/syllabic ( /iy/, /piy/, /tiy/, /diy/, /uw/, /m/, /n/ ) as well as 4 words(pat, pot, knew and gnaw)KARA ONE BIBREF17 , composed of multimodal data for stimulus-based, imagined and articulated speech state corresponding to 7 phonemic/syllabic ( /iy/, /piy/, /tiy/, /diy/, /uw/, /m/, /n/ ) as well as 4 words(pat, pot, knew and gnaw)",
        "Pointer-Gen, Pointer-Gen+Pos, Pointer-Gen+Same-FT, Pointer-Gen+Pos-FT, Pointer-Gen+RL-ROUGE, Pointer-Gen+RL-SEN",
        "Naïve Bayes (NB), Logistic Regression (LR), Support Vector Machine (SVM), Random Forests (RF), Gradient Boosted Trees (GBT),  Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN)Naïve Bayes (NB), Logistic Regression (LR), Support Vector Machine (SVM), Random Forests (RF), Gradient Boosted Trees (GBT), CNN, RNN",
        "uni-directional model to augment the decoderbi-directional language model to augment the sequence to sequence encoder ,  uni-directional model to augment the decoder",
        "One can think $(1-p_{i1})$ as a weight associated with each example, which changes as training proceeds. The intuition of changing $p_{i1}$ to $(1-p_{i1}) p_{i1}$ is to push down the weight of easy examples. For easy examples whose probability are approaching 0 or 1, $(1-p_{i1}) p_{i1}$ makes the model attach significantly less focus to them. Figure FIGREF23 gives gives an explanation from the perspective in derivative: the derivative of $\\frac{(1-p)p}{1+(1-p)p}$ with respect to $p$ approaches 0 immediately after $p$ approaches 0, which means the model attends less to examples once they are correctly classified.associates each training example with a weight in proportion to $(1-p)$, and this weight dynamically changes as training proceeds",
        "Reward of 11.8 for the A2C-chained model, 41.8 for the KG-A2C-chained model, 40 for A2C-Explore and 44 for KG-A2C-Explore.KG-A2C-chained and KG-A2C-Explore both pass the bottleneck of a score of 40",
        "Bayesian model of garg2012unsupervised as our base monolingual model",
        "UnanswerableOriginal transcription was labeled with additional labels in [] brackets with nonstandard pronunciation.",
        "A semi-character based RNN (ScRNN) treats the first and last characters individually, and is agnostic to the ordering of the internal charactersprocesses a sentence of words with misspelled characters, predicting the correct words at each step",
        "Bulgarian, Croatian, Czech, Danish, English, French, German, Indonesian, Italian, Norwegian, Persian, Polish, Portuguese, Slovenian, Spanish and SwedishBulgarian, Croatian, Czech, Danish, English, French, German, Indonesian, Italian, Norwegian, Persian, Polish, Portuguese, Slovenian, Spanish , Swedish",
        "NCEL consistently outperforms various baselines with a favorable generalization ability",
        "YesYes",
        "error detection system by Rei2016error detection system by Rei2016",
        "clinical notes from the CE task in 2010 i2b2/VAclinical notes from the CE task in 2010 i2b2/VA ",
        "ecause this process is similar to the cloze task in BERT's pre-train process, therefore by using the ability of the contextual language model the decoder can generate more fluent and natural sequences.",
        "Unanswerable Paraphrase Database (PPDB) ,  book corpusUnanswerable",
        "Unanswerable",
        "no evidence of depression, depressed mood, disturbed sleep, fatigue or loss of energyThe annotations are based on evidence of depression and further annotated by the depressive symptom if there is evidence of depression",
        "BC5CDR-disease, NCBI-disease, BC5CDR-chem, BC4CHEMD, BC2GM, JNLPBA, LINNAEUS, Species-800BC5CDR-disease, NCBI-disease, BC5CDR-chem, BC4CHEMD, BC2GM, JNLPBA, LINNAEUS, Species-800",
        "using the machine translation platform Apertium machine translation platform Apertium BIBREF5",
        "AllWords model by counting the frequencies of all the remaining words and training a multinomial Naive Bayes classifier",
        "The baseline system for the SLC task is a very simple logistic regression classifier with default parameters. The baseline for the FLC task generates spans and selects one of the 18 techniques randomly.SLC task is a very simple logistic regression classifier, FLC task generates spans and selects one of the 18 techniques randomly",
        "They compare with the following models: by Pedersen (2017), by Pramanick and Das (2017), by Mikhalkova and Karyakin (2017),  by Vadehra (2017), Indurthi and Oota (2017), by Vechtomova (2017), by (Cai et al., 2018), and CRF.",
        "By assigning a political bias label to each news article and training only on left-biased or right-biased outlets of both disinformation and mainstream domainswe also account for political biases inherent to different news sources, referring to the procedure proposed in BIBREF2 to label different outlets. Overall we show that we are able to classify credible vs non-credible diffusion networks (and consequently news articles) with high accuracy (AUROC up to 94%), even when accounting for the political bias of sources (and training only on left-biased or right-biased articles). We observe that the layer of mentions alone conveys useful information for the classification, denoting a different usage of this functionality when sharing news belonging to the two news domains. We also show that most discriminative features, which are relative to the breadth and depth of largest cascades in different layers, are the same across the two countries.",
        "ancient Chinese history records in several dynasties (about 1000BC-200BC) and articles written by celebrities of that eraAncient Chinese history records in several dynasties and articles written by celebrities during 1000BC-200BC collected from the internet ",
        "EnglishEnglish English",
        "Answer with content missing: (Data section) Chinese with version 5.1 of the Chinese Penn Treebank (CTB)",
        "eight layers",
        " the same datasets as BIBREF7same datasets as BIBREF7",
        "MEDDOCAN, NUBes-PHIMEDDOCAN, NUBes ",
        "Unanswerable",
        "Coverage, Avg. MCC and avg. +ve F1 scorestrategy formulation ability, we introduce a measure called Coverage( INLINEFORM0 ), To evaluate the predictive performance, we use Avg. MCC and avg. +ve F1 score",
        "YesNo",
        "Galatasaray, FenerbahçeGalatasaray , Fenerbahçe ",
        "Irony Classifier, Sentiment Classifier for Irony, Sentiment Classifier for Non-irony, transformation from ironic sentences to non-ironic sentences",
        "pays attentions to adjacent characters and casts a localness relationship between the characters as a fixed Gaussian weight assuming the weight relies on the distance between charactersGaussian-masked directional attention can be described as a function to map queries and key-value pairs to the representation of input, Gaussian-masked directional attention expects to pay attention to the adjacent characters of each positions and cast the localness relationship between characters as a fix Gaussian weight for attention, Gaussian weight only relys on the distance between characters",
        "Facebook status update messagesFacebook status update messages",
        " The features extracted from CNN.",
        "number of clusters, seed value in clustering, selection of word vectors, window size and dimension of embeddingdifferent number of clusters, different embeddings",
        "column Ens Test in Table TABREF19",
        "8,275 sentences and 167,739 words in totalThe corpus comprises 8,275 sentences and 167,739 words in total.",
        "UnanswerableUnanswerable",
        "text classification for themes including sentiment, web-page, science, medical and healthcare",
        "bag-of-words model, CNN",
        "By 14 times.up to 1.95 times larger",
        "36066946",
        "MLPEusboost, MWMOTE",
        "YesYes",
        "YesUnanswerable",
        "0.51150.6103",
        " Wall Street Journal (WSJ) portion of the Penn TreebankUnanswerable",
        "By conducting a survey among engineersUnanswerable",
        "SimpleQuestions, WebQSPWebQSP, SimpleQuestions"
    ],
    "predict": [
        "No, the ISR is not necessary for transgene reactivation.",
        "The experimental techniques used to study quantum dot structures in this research included improvements to experimental equipment and techniques such as generation of shock waves, interface formation methods, schlieren facilities, and image recognition techniques.",
        "The ICD stands for Information Communication Device.",
        "Sloping (tumbling home) the sides ensures that the fuselage section is conical when formed from panel parts rather than cylindrical. This results in proper fitment with flat-top longerons and avoids bowing of the sides during assembly, which can lead to a banana-shaped box section. Without this sloped design, the shape would not match what's needed for the completed fuselage structure.",
        "Electricity is used in everyday life for various purposes such as heating, cooling, lighting, charging devices, powering electronics, and many other applications.",
        "Commander",
        "The three synthetic types of vitamin K are vitamins K3, K4, and K5.",
        "Yes, individual molecules of indeno[1,2-a]fluorene can switch between open-shell and closed-shell states.",
        "Electric field",
        "The recommended daily intake of vitamin K for adult women and men is 120 μg.",
        "The SI unit of power is the watt (W).",
        "The main advantage of a horizontal business model for mobile devices is flexibility. As costs drop and the market expands, vendors like HTC are required to offer wide-ranging phone models based on different SoCs, allowing them to cater to various customer needs efficiently without focusing solely on a specific niche.",
        "Brooksley Elizabeth's first husband is not specified in the given content.",
        "The main methodology used in the research is based on BIBREF7's method.",
        "The function β(r) is determined by solving the differential equation \\(\\beta\\cdot\\beta' = \\frac{C}{r^2}\\), where \\(C\\) is a constant. This leads to the solution\n\n\\[\nB(r) \\equiv \\beta(r)\\cdot\\beta'(r) = C \\frac{\\mathrm{d} r}{r^2}.\n\\]\n\nBy integrating both sides, we obtain:\n\n\\[\n\\beta(r) = -\\int \\frac{\\mathrm{d} r}{C r^2} = \\pm \\frac{1}{C} \\sqrt{\\frac{r_0}{r}},\n\\]\nwhere \\(r_0\\) is the initial radial distance. The minus sign makes β positive for infalling particles, ensuring consistency with the problem setup.",
        "70-75 meters",
        "The vaccines trialed against were pertussis, measles, mumps, rubella, tetanus, diphtheria, Hib disease, and chickenpox.",
        "The size chains used in the benchmarking were not specified in the given text.",
        "Five experiments were demonstrated.",
        "The three teams that used conflict optimization in the CG:SHOP 2022 challenge were Lasa, Gitastrophe, and Shadoks.",
        "The court in In re Ferguson focused on the intangibility of the compared data when evaluating the 'transformation' prong of the Bilski test. It concluded that there was no transformation without physical manifestation or machine involvement as determined by precedent such as Abele decision, which limited the requirements for patent eligibility under Section 101.",
        "The transition probability affects the learning rate by determining how frequently the agent explores different environments. As the transition probability increases, the evolved learning rate decreases, leading to slower and more stable convergence within environments where stays are rare. This is consistent with the behavior observed in static agents but contrasts with the scenario of moving agents with a higher frequency of environment transitions requiring faster learning to adapt quickly.",
        "Ultracold neutral plasmas focused on in this study form via kinetic rate processes from state-selected Rydberg gases.",
        "Wearable sensors capable of estimating physical activity levels and physiological outcomes of older adults include accelerometers, gyroscope, electrodermal activity (EDA), photoplethysmography (PPG). Additionally, ambient sensors capture movement patterns and behaviors.",
        "Mary told the disciples that Jesus was ascending to heaven and that she had seen Him there, confirming their belief in His divinity.",
        "The future direction mentioned in the conclusion is \"Research on puns for other languages such as Chinese.\"",
        "The baseline serves as a reference point for layout measurements.",
        "The new Iraqi Body Count organization provides data and support for the number of civilian deaths in Iraq, allowing supporters of the war to claim it is improving conditions there despite criticism.",
        "The main advantage of the proposed method in terms of computation time is that it significantly reduces computational efficiency compared to traditional numerical methods like Runge-Kutta and convolution. The proposed method achieves faster execution times by obtaining an explicit response solution directly at a specific time, rather than requiring integration over a larger range for approximate solutions. This results in substantial improvements in the speed of computation.",
        "Based on the content provided about Njoroge and his family's background, he has two brothers: Kamau (who works as an apprentice) and Boro (the eldest son who had experiences during World War II).",
        "Del Bigtree and his team at ICAN compiled the 88-page letter.",
        "The content provided does not contain information about when Weep Not, Child was first published. The text discusses topics related to parenting, psychology, and historical figures, but does not mention any books by that name or their publication dates.",
        "Dendritic spines contain actin and complex networks of proteins linking extracellular signals with the actin cytoskeleton.",
        "14,520 attendees.",
        "Justice Kennedy argued about Quill in Direct Marketing Ass'n v. Brohl that the website was not doing a civilian count before leaving. This is because the company received an email from Reuters stating how many deaths were reported by the news agency.",
        "Environment fluctuation and uncertainty control the reliance on plasticity, while the form of the emerging plasticity rule is determined by details of the task.",
        "The bowing problem encountered when building the fuselage sides.",
        "Goodwin became a Naval aviator in August 1928.",
        "TYPE C and TYPE A fast charging protocol chips are available.",
        "The given content does not provide specific details about when Born resigned as chairperson of the CFTC. The text discusses early life, congenital heart defects, digital data use, and historical practices related to mourning, but does not mention any resignation from a government position. Therefore, based on the provided information, it is not possible to determine when Born resigned from his role at the CFTC.",
        "Mufti-e-Azam-e-Hind received Khilafat from Sayyiduna Noori Mia in various Orders including Qaderi Silsila and Chishti. He also received it from his blessed father, A'la Hazrat Ash Shah Imam.",
        "The reason given by Governor Rick Scott for not implementing a prescription drug monitoring database in Florida was the absence of such a database.",
        "Wallace electorate.",
        "The 2017 general election was held on 23 September.",
        "Long Term Capital Management (LTCM)",
        "The dynamical behavior of the anisotropic order parameter $m$ following a quench to the critical point is well described by FIG. 10 and other plots provided in the letter.",
        "The recommended space for using the VR headset is at least 2 meters in length and width to ensure safety during VR experiences.",
        "The three phases of the author's preaching process are: theological phase, questioning, answering, and exhorting with authoritative words from God.",
        "KSTP switched to a sports radio format in 1970.",
        "RoBERTa and BERT were the best performing models for Spanish in Track-1.",
        "Toby Schindelbeck's observation about the police is that it showed where someone buried a woman.",
        "The program chair of this conference is Peter Denning.",
        "The conduction gap depends strongly on both the applied strain direction and the transport direction in graphene. For small strains, it can open with a few percentage points. Larger gaps are possible for higher strain percentages but require larger shifts of Dirac points along the $k_y$-axis. The full understanding and optimization of this phenomenon would benefit from further systematic investigations into strain-dependent effects on conduction properties.",
        "1887",
        "The three subsets of parameter space V are: \\( V^+ \\), \\( V_0 \\), and \\( V^- \\).",
        "Ngotho is fired from his job at Mr. Howlands' due to attacking Jacobo during the workers' strike.",
        "The reasons for the lack of data sharing in archaeobotany include technological limitations and resistance among some researchers. There is also limited formal guidance on data-sharing practices within the field.",
        "Goodwin commanded VC-10 Squadron during the initial landings of Marines on Saipan.",
        "The bigger the receptive field size, the more complete shapes can be reconstructed using DSP.",
        "The interlayer Berry connection polarizability is significant because it explains the unique rectification functionality and the ability to probe chiral symmetry in bilayer systems.",
        "Yes, the denoiser can be applied to circuits with non-Clifford noise.",
        "Professor Tulis's forthcoming book is about Political Theory and American Politics.",
        "A media application determines the context of an event by processing associated data using various content-recognition modules/algorithms. This involves analyzing spoken words and actions during and around the event to better understand its context.",
        "The title of one of Kam W. Leong's publications in the Journal of Controlled Release is not explicitly mentioned in the given content.",
        "The study concluded that pediatric vaccines trialed against genuine placebo had been found ineffective and that no other vaccine was tested with a true placebo. The comparison among toxic products without a true placebo group was the main focus of the research.",
        "The scoring engine generates a stream of content for the channel based on candidate content items that match the channel category and optionally another channel attribute.",
        "Symptoms of vitamin K deficiency can include anemia, bruising, nosebleeds, gum bleeding, heavy menstrual bleeding, and changes in blood clotting.",
        "The security parameter for AES-256 block cipher is 256 bits.",
        "Mobile Device Management (MDM) refers to centralized control of an entire fleet of mobile devices (smartphones and tablets), including their configuration settings. It involves applying and ensuring pre-defined policies for these devices, while also managing the security aspects related to connectivity and transmitted content.",
        "The models used for dialect identification included XLM-RoBERTa, BERT, ELECTRA, RoBERTa, and GPT-2.",
        "Hosting Subscriber is responsible for ensuring reasonable server load. Use of prohibited software is forbidden, and Broadjam has the right to temporarily or permanently remove Hosting Subscriber's Website from servers if threats to network stability are present. If Hosting Subscriber's password is lost, it must be immediately reported and replaced promptly by the hosting provider.",
        "The vacuum processing system arranges all vacuum processing chambers in parallel for a unified configuration.",
        "The average magnetic moment per column in Ge$_{1-x}$Mn$_{x}$ films is not directly provided in the given content. However, based on the context of the text discussing different phases and growth conditions, it suggests that the presence of Mn-rich nanocolumns and Ge$_{3}$Mn$_{5}$ clusters implies a magnetic moment distribution depending on these structures. To get an accurate average magnetic moment per column, further detailed experimental results or simulations would be needed.",
        "No, there is no explicit evidence of heaven and hell.",
        "The given text does not provide specific information about when BC leaves Boston.",
        "Benefits of using binary variables in the SLAS formulation:\n\n- Allows incorporation of sparse and irregularly sampled training data\n- Reduces number of latent variables needed for harmonic effects\n- Enables fast prediction generation after training phase\n- Serves as an effective strategy reformulation into a Markov Decision Process (MDP) with binary decision making.",
        "On-line support groups.",
        "Symptoms of alpha thalassemia major include:\n- Anemia: Red blood cells are often small and abnormal, leading to fatigue and weakness.\n- Growth issues: Children may experience delayed growth and development compared to their peers.\n- Paleness: Skin and eyes can appear pale or yellowish due to anemia.\n- Rapid heart rate: The body tries to compensate for the lack of oxygen by speeding up its heartbeat.",
        "Simon English became the leader of the National Party on 27 February.",
        "Smartphones are more compact and power-constrained compared to tablets, with limited battery capacity and thermal dissipation limitations, while tablets have a broader range of designs due to their larger power budget for SoCs. Tablets typically don't feature cellular modems, whereas smartphones integrate them as necessary.",
        "The sticking point in the political showdown over the budget is how much spending to cut.",
        "The State Government is responsible for appointing an officer (Director of Town and Country Planning) as per Notification in Official Gazette. Other officers can be appointed by the State Government if deemed fit.",
        "The framework captures reduced-order dynamics by using complex-valued latent variables in the latent space and treating them independently. This allows for interpretable latent dynamics while enabling training with fewer parameters.",
        "To level up in early levels, you should focus on attacking nearby zones and continue doing so as you progress. Keep deploying your base and earning experience points (XP) to gain access to more advanced options.",
        "The electron correlation parameter, $\\Gamma_e$, is defined in Equation (\\ref{eqn:gamma_e}) as:\n\\[\n\\Gamma_e = \\frac{e^2}{4\\pi \\epsilon_0 a_{ws}} \\frac{1}{k_B T_e}\n\\]\nwhere $a_{ws}$ is the Wigner-Seitz radius related to electron density.",
        "Players can skip dialogue on the quest map by pressing 'SKIP'.",
        "4 years",
        "The IAF is considering the Boeing C-17 Globemaster III for acquisition besides the An-32.",
        "Exposure to direct sunlight may cause permanent yellow spot damage on the screen.",
        "Craig wants to find his own place because he enjoys renting from someone who smokes. It's good for him since the lady is responsible and has been doing well financially. Craig is becoming more aware of costs and taking responsibility in this regard. He also finds it difficult to accurately translate proper nouns, personal pronouns, ancient specific appellations, and special words into modern Chinese due to their low accurate rates.",
        "At dawn or dusk, the brain reduces the resolution of focused objects due to low light conditions.",
        "The group requested that the Connecticut DEEP Commissioner.",
        "Power-law functions.",
        "Brooksley Born received the ACS Chemical Technology Student Recognition Award in 2007.",
        "The paper aims to use text and other features together in deep learning models for better performance.",
        "Accounting for path preference improves the robot's belief update by reducing over-confidence in predicting the goal likelihood, making it easier to reach the correct goal.",
        "Two ground states observed for indeno[1,2-a]fluorene on NaCl surfaces: an open-shell state (5OS) and a closed-shell state with a para-quinodimethane moiety.",
        "The main focus of the research paper is on exploring how multitask learning can improve performance in sentiment classification and fine-grained sentiment classification tasks. Specifically, it examines whether jointly training models for ternary and fine-grained sentiment classification problems can enhance state-of-the-art results compared to individual training methods for each task.",
        "The rationality coefficient used in the observation model is γ h.",
        "Kamau",
        "Thalassemias are classified based on the globin protein affected: alpha thalassemia for mutations affecting the alpha globin chain and beta thalassemia for mutations affecting the beta globin chain.",
        "The advantage of decorrelating the data before running the PLS algorithm is improved performance by enhancing its ability to analyze dependent observations effectively.",
        "C-GDBN",
        "Some potential applications of ferromagnetic semiconductors include:\n- Spin injection into non-magnetic semiconductors\n- Electrical manipulation of carrier-induced magnetism in magnetic semiconductors\n- Development of nanodevices such as memory nanodots and nanochannels for spin injection\n- Potential utilization of narrow graphene nanoribbons and graphene nanomesh lattices for applications requiring precise control over lattice geometry and edge disorder.",
        "62",
        "The main topic of the text is the proposal and evaluation of the user-topic-comment neural network (UTCNN) for post stance classification on forum-style social media platforms.",
        "The potential of SNNs (Simple Spiking Neural Networks) lies in their ability to model the hierarchical and functional properties observed in both macaques and mice's visual systems. This includes understanding how these animals process incomplete outlines into complete shapes and organize disconnected visual features, tasks that are crucial for visual processing.",
        "Deputy Prime Minister",
        "0.32",
        "The specific-heat ratio affects the average motion of the bubble. It contributes little to the initial stages but significantly influences later stages such as after the shock wave passes through it.",
        "The scaling form for the alternative order parameter O is not explicitly stated in the given content.",
        "For different measures of CPUE (standardised versus unstandardised), relationships between catch per set and fishing behavior variables differ. Specifically:\n- For unstandardised CPUE: There is a positive relationship with number of hooks for threatened and regulated species, but a significant negative relationship with standardised CPUE.\n- For standardised CPUE: The negative relationship persists, suggesting diminishing returns above low levels of effort, indicating that maximum sustainable yield was being exceeded.",
        "No, someone cannot sell or modify the Agency Spotter Content.",
        "The research opportunity that is mentioned involves studying the effects of Brazilian Jiu Jitsu and psychotherapy on helping individuals with autism develop subjective awareness of others.",
        "The ground truth for fake news is established by manually annotating 1327 tweets as containing or not containing fake news. This process was carried out by a single person to ensure consistency across the dataset.",
        "The GhostVLAD approach aggregates frame-level features into a single utterance level feature through multilingual pooling.",
        "1.88%",
        "Additional features and context proposed: Incorporating KL divergence in certain algorithms like GE-FL provides better results for unbalanced datasets compared to maximum entropy and neutral features. The method also leverages feedback from instances and features used interlacedly. Additionally, a hierarchical approach using local features is proposed for more effective learning of context.",
        "They looked at different Facebook pages (and therefore domains and stances). The specific pages were chosen based on intuition and considering available datasets for evaluation.",
        "No.",
        "Word analogy task and named entity recognition (NER) task.",
        "The datasets used for evaluation are the three standard datasets mentioned in Section SECREF3. These datasets are used for evaluating the effectiveness of embeddings and will follow the methodology described by BIBREF7 for cross-lingual transfer gaps. The resulting multilingual datasets, which do not offer any support in either training or evaluation but focus on outlining the wide potential and applicability of Multi-SimLex datasets for multilingual and cross-lingual representation learning evaluation, are also used.",
        "The approach compares favorably to other WSD (Word Sense Disambiguation) approaches using word embeddings by demonstrating superior feature discrimination capabilities in embedding generation. It involves the use of Gaussian emission HMMs with observed word embeddings but does not attempt learning new embeddings, unlike BIBREF9. Instead, it extends existing models like HMM or dependency trees with multinomial distributions parameterized by word (or tag) embeddings, as seen in BIBREF10, BIBREF11, and BIBREF12.",
        "The ensemble method works by training multiple models (the ensemble) and then averaging their predictions. This approach aims to improve performance by combining the strengths of individual components rather than relying solely on one model's results. In this case, the authors use a discrete Boltzmann method (DBM) for prediction updates during training.",
        "The datasets originate from WordNet, GNU Collaborative International encode locations, and various expert knowledge resources such as Flickr tags.",
        "Spanish",
        "The dataset used for sentiment analysis includes Semeval 2015 Task 11 BIBREF0.",
        "58.54% for Track-1 and 85.61% for Track-2",
        "Yes, they experimented with this new dataset.",
        "The datasets used in the experiment include NER (Named Entity Recognition) English datasets such as CoNLL2003 and OntoNotes5.0, and Chinese datasets like MSRA and OntoNotes4.0.",
        "Electrical lighting sector",
        "They compared their models with existing strong summarization baselines.",
        "The three regularization terms are:\n1. A regularization term associated with neutral features.\n2. The maximum entropy of class distribution regularization term.\n3. The KL divergence between reference and predicted class distribution.",
        "The baselines are compared with different choices of pre-trained models such as BERT, RoBERTa, GloVe.",
        "They improved in three areas: improving model performance in a challenging domain, enhancing system robustness, and enhancing personality learning for chatbots.",
        "Their model improves interpretability by incorporating sparse attention mechanisms instead of the traditional softmax transformer. Sparse attention allows for zero probabilities in irrelevant words and can prune redundant head attention heads to reduce redundancy, enhancing interpretability while slightly improving performance.",
        "The baseline was the reference for the top longerons in the new layout.",
        "The metrics used for evaluation are BLEU score, contrastive evaluation of translation of several discourse phenomena, and human evaluation.",
        "The attention module is pretrained on multiple available modalities such as words, characters, images, etc., to produce a single vector representation with aggregated knowledge among these modalities.",
        "Stylistic features obtained include graph structure and cognitive features in an NLP processing system.",
        "Encoder has a Bert-based architecture with a randomly-initialized Transformer decoder.",
        "No, WordNet is not useful for taxonomic reasoning tasks.",
        "The baselines were compared for their performance improvements over simplified training data.",
        "5,191 users were looked at for verification in their case.",
        "BLEU score, contrastive evaluation of translation of several discourse phenomena, human evaluation.",
        "They create sentiment labels and emotion lexica on their dataset.",
        "4096",
        "The three evaluation tasks used for evaluation are:\n1. Word analogy task\n2. Named entity recognition (NER) task",
        "The improvement in performance for Estonian in the NER task is 39.8 F1 compared to the No-answer (NA) baseline.",
        "The text does not provide specific details about what backgrounds the individuals have.",
        "Yes, this paper introduces an unsupervised approach to spam detection.",
        "Devanagari languages and Welsh.",
        "They compared their LSTM-based models with other LSTM models.",
        "The provided training set consists of 450 utterances.",
        "The human judgements were assembled through 100 randomly sampled instances.",
        "Yes, they test their framework performance on commonly used language pairs like English-to-German.",
        "Models are evaluated by comparing the machine-generated labels against human annotated samples in cross-lingual systems.",
        "BLEU score, contrastive evaluation of translation for discourse phenomena, and human evaluation.",
        "Source domain: Electronics  \nTarget domain: Beauty",
        "They compare their method with RNN-based models like LSTM and Transformer. Specifically, they contrast it with previous RNN models in terms of performance on the new dataset built for experiments.",
        "NeuronBlocks includes modules for encoder, sub-GCN, and decoder in neural network-based models to classify emotions.",
        "The datasets used in the experiments were NER datasets and emotion datasets. Specifically, the English datasets included CoNLL2003 and OntoNotes5.0, while Chinese datasets improved F1 scores by +0.97 and +2.36 on MSRA and OntoNotes4.0 respectively. For Emotion datasets, the French and German datasets were used with specific preprocessing methods derived from Wikipedia articles.",
        "The baselines were compared across different datasets and evaluation metrics such as accuracy and F1 score.",
        "The languages they use in their experiment are unspecified.",
        "They test their method on different tasks. Specifically, they use it in:\n\n1. An emotion labeling task (Affective development) with 250 annotated headlines.\n2. A system evaluation using another set of 1000 headlines (Affective test).\n3. A semantic analogy test set and overall results for the original GloVe embeddings.\n4. Zero-shot testing where the actual test set is used in a different language (XLM-R).",
        "Yes, they use pretrained embeddings. Specifically, BioBERT uses pre-trained word embeddings for the first step and relation names are randomly initialized for the second step.",
        "Yes, PolyReponse was compared against a baseline system (not explicitly stated but implied based on context).",
        "They obtain psychological dimensions of people by using the Positive Emotion and Negative Emotion categories from the Linguistic Inquiry and Word Count (LIWC) dictionary to quantify the emotional orientation of texts. This involves identifying words that correlate with different psychological states based on their association with human emotions, such as those described in the context about \"happy,\" \"pretty,\" and \"good.\"",
        "ML methods aim to identify argument components such as claim, premise, backing, rebuttal, and refutation.",
        "Length 5",
        "The Twitter dataset is large-scale and suitable for building robust ASR models in Persian.",
        "The 12 languages covered in the content are: French, German, Dutch, Russian, Spanish, Italian, Turkish, Persian, Swedish, Mongolian, and Chinese.",
        "The two datasets used in this paper are IEMOCAP and WeiboDial.",
        "Yes, some pipeline components were based on deep learning models, including:  \n1. A language identification model  \n2. Language-specific models for each language  \n3. Text classification models (CNN BIBREF3 and RCNN BIBREF0) with hyperparameters tuned from their work  \n4. SVM models integrated with deep learning models  \n5. Pure-text CNN model without user information  \n6. Pipeline-based method heavily dependent on dependency parsing",
        "The quality of the data is empirically evaluated by comparing the model's performance when trained and evaluated with monolingual versus parallel data.",
        "The audio and text sequences are encoded separately using RNNs (Recurrent Neural Networks), combined using feed-forward neural models, and attention mechanisms focus on specific emotional parts of transcripts.",
        "The question is incomplete and refers to \"their\" model, but it asks how much their model improved. The content discusses improvements on baselines through semi-supervised training methods but does not provide specific details about the model's performance improvement. Therefore, without more context on the actual changes made by the research team compared to existing models, it is impossible to give an accurate answer based solely on this text.",
        "2 humans evaluated the results.",
        "The definition used for \"going viral\" in this context refers to tweets that were retweeted more than 1000 times.",
        "The basic neural architecture that performs best by itself is the sequence-to-sequence (seq2seq) model.",
        "The source of the data for the BLEU performance measurements is two test sets: tst2013 and tst2014.",
        "Deep learning methods are used for RQE.",
        "The benchmark dataset is the one billion word language modeling benchmark dataset BIBREF21. The quality of this dataset is high.",
        "The decoder has a text encoder-decoder architecture similar to MT models.",
        "No.",
        "The UPA model is best performing among author's submissions. It had the highest overall performance across thread lengths from 1 through 7 posts and INLINEFORM1 posts. However, its performance dropped steeply on threads of length INLINEFORM3.",
        "Baseline was laid perpendicular to the layout of the new developed side panel and referenced at the mid point of the firewall for the designed dimension.",
        "The highest recall score was achieved by the RNN models with context tweets for \"abusive\" tweets.",
        "The paper explores embedding techniques. Specifically, it introduces two types of embeddings: INLINEFORM0 for each word/mention and INLINEFORM1 for multiple sense embeddings, where INLINEFORM2 refers to an entity embedding while INLINEFORM3 and INLINEFORM4 differentiate between them as discussed in the text. Additionally, there is a focus on models that consider co-occurrence information and structured entity relations encoded by INLINEFORM5 using hyperlinks and INLINEFORM6 modeling structured entity relations in KBs.",
        "They match words before reordering them by using an ancient Chinese dictionary to address unmatched characters and apply Inverse Document Frequency (IDF) to weigh matching words. Then they use CFILT-preorder system rules for English sentence reordering based on Indian language word order improvements tuned specifically for Hindi.",
        "Yes, the paper explores extraction from electronic health records.",
        "The experts were randomly sampled from 100 instances for annotation.",
        "For painting embedding: CNN-RNN based image-to-poem net combined with seq2seq model using parallel text corpus. For language style transfer: A fine grained model for text style transfer uses global attention instead of local attention.",
        "The RNN layer performs better on top of BERT compared to the transformer layer.",
        "Yes, the authors hypothesize that humans' robustness to noise is due to their general knowledge.",
        "The content does not directly mention cyberbullying topics they addressed but focuses on other aspects such as spam, legitimate user behavior, and fake accounts. Cyberbullying is not explicitly discussed in the provided text.",
        "The new context representation is obtained by extracting glosses of all possible senses (here \\( N = 4 \\)) of the target word from WordNet and adding [CLS] and [SEP] marks to make it suitable for input with BERT.",
        "4",
        "2% higher quality",
        "The analyzed corpora exhibit significant imbalance, with one class dominating over others significantly.",
        "Penn Treebank BIBREF13",
        "MLE, RL, GAN, SeqGAN.",
        "The classifiers used are intent classifiers for resetting dialogue state and activating separate restaurant booking flow. Additional feature values suggest potential gain from combining base classifiers into an ensemble of models.",
        "OpenNMT, AllenNLP, NLTK, Stanford CoreNLP, TwitterNLP.",
        "Track-1 and Track-2 datasets are used for experiments.",
        "Existing approaches to this task are not fully unsupervised due to their reliance on gold POS tags from an original experimental setup designed for Domain Name Verification (DMV). However, inducing dependencies directly from words represents a more realistic experimental condition, especially when gold POS tags are scarce. The paper compares various existing methods and aims to provide guidance for tackling extremely low-resource translation tasks by introducing novel approaches within the argumentation mining field.",
        "Yes, they use attention.",
        "The three datasets used for evaluation are standardly used datasets for evaluating emotion classification. These datasets have been described in Section 3.",
        "Sentiment classification dataset: Fine-grained sentiment classification with five-point scale.",
        "Yes.",
        "The provided text does not directly state whether the datasets for sentiment analysis are balanced. It mentions constructing unbalanced datasets with class distributions as 1:2, 1:3, and 1:4 by randomly removing positive documents from a movie dataset. The content suggests that existing NLP systems cannot accurately perform sentiment analysis on the dataset used in experiments due to its unbalanced distribution, but it does not explicitly confirm that all datasets are balanced.",
        "The invertibility condition ensures the Jacobian determinant of the transformation is always equal to one, which guarantees volume preservation and natural satisfaction.",
        "The proposed qualitative annotation schema categorizes gold standards based on linguistic complexity, required reasoning, background knowledge, and factual correctness. It uses high-level categories for question, expected answers, and context annotations. The schema also includes a metric based on lexical cues to approximate the reading (micro) average F1 score of the annotations, which was found to be 0.82, with more than two-thirds of the labels agreed upon by both annotators.",
        "The sizes of both datasets are not explicitly stated in the given content. To find this information, you would need to refer to Table TABREF3, which is mentioned in the text as summarizing the used corpora and their sizes.",
        "Baselines refer to pre-existing models used for comparison in the study.",
        "English and Swedish (en-Sv)",
        "The models used in the experiment are NMT (Neural Machine Translation) and SMT (Statistical Machine Translation).",
        "Yes, the answered questions measure for the usefulness of the answer.",
        "GloVe pretrained word embeddings and BioBERT model used in experiments.",
        "The results on the new dataset are presented in Table TABREF21 and described in section 4. The research shows that existing NLP systems struggle to accurately perform sentiment analysis of political tweets within the dataset used for experimentation, and human labeling yields accuracy results far surpassing those of automated systems. Future work aims to use a crowdworker-labeled dataset balanced among classes and train a new machine learning-based NLP system specifically for tweet analysis with transfer learning capabilities. Results are reported as averages from multiple model runs on one dataset.",
        "The combination of rewards for reinforcement learning in this paper includes two types designed specifically to measure the accuracy of irony and preserve sentiment: one for irony accuracy and another for preserving sentiment.",
        "The authors demonstrate limitations in their model due to challenges with polysemy, rare outliers, errors introduced during feature engineering, inconsistencies between methods' strengths and weaknesses, and the need for further research on mixed results from feature engineering.",
        "The benchmarks compared in the content were Facebook pages for QA purposes.",
        "They provided experimental results on how their model performed under different temperature settings.",
        "The hashtags for experiments were sourced from two datasets: \n- STAN INLINEFORM0 consisting of 1,108 unique English hashtags and their associated tweets, created by BansalBV15;\n- STAN INLINEFORM1 containing all 12,594 unique English hashtags, created by experts.",
        "The corpus contains speakers with potentially different accents.",
        "The TF weighted word subspace can effectively represent the context of corresponding text by incorporating frequency-related information.",
        "Baseline model",
        "No, SemCor3.0 is not reflective of English language data in general. It contains specialized training and development/test sets that are realistic for real-world news data, distinguishing it from broader English usage.",
        "The Augmented LibriSpeech dataset contains 0.46M training pairs.",
        "The ILPRL dataset was used.",
        "They use large BERT models.",
        "Yes, the automatically constructed datasets are subject to quality control. Specifically, they ensure a focus on syntax rather than selectional-preferences based cues by replacing multi-hop sentences with random words with the same part-of-speech and inflection. This approach aims to maintain a controlled experimentation environment while still covering various syntactic phenomena.",
        "Yes, the images from a specific domain.",
        "The performance on emotion detection was significantly improved by using pre-trained sentiment, emotion, and personality models, outperforming state-of-the-art results across different datasets.",
        "The tagging scheme employed is INLINEFORM5.",
        "No.",
        "Robustness is determined by the model's ability to perform well across multiple concepts without significant errors spreading. A lower sensitivity metric indicates greater robustness in word recognition models.",
        "Other sentence embeddings methods are evaluated using SentEval transfer tasks.",
        "The method's improvements in F1 for English NER datasets are +0.29 for CoNLL2003 and +0.96 for OntoNotes5.0. For Chinese NER datasets, the improvements are +0.97 on MSRA and +2.36 on OntoNotes4.0.",
        "Tasks 1 and Task 2",
        "The baselines compared against were:\n- Majority class baseline\n- Neural Checklist Model adapted to use neural network (NN)\n- Simple Encoder-Decoder model with ingredient attention (Enc-Dec)",
        "The core component for KBQA is the parse label used to categorize different entities and their relationships.",
        "The baseline models are those that were used as references for comparison in experiments.",
        "Unwarranted inferences and stereotype-driven biases.",
        "Multiple pooling strategies including NetVLAD pooling, Average pooling, and Statistics pooling (as proposed in X-vectors) are explored.",
        "The models experimented with were NMT (neural machine translation) and SMT (statistical machine translation).",
        "No, they report results on English data only.",
        "The authors experimented with ILP-based summarization algorithm alongside several other summarization algorithms provided by the Sumy package.",
        "The previous state of the art for this task was not specified in the given content.",
        "The component that is least impactful in this context is \"learning models.\"",
        "The corpus for the task is a freely available lemmatized, POS-tagged and spelling-normalized diachronic corpus of German texts from the 16th to the 20th century.",
        "The languages experimented with in this context are seven Indian languages.",
        "The model performance on target language reading comprehension is not evaluated reliably by current data due to weaknesses in superficial text analysis aspects.",
        "The performance difference between the proposed model and baselines is shown to be significant in all ranges of relative distances. Specifically, it improves on Hybrid when distance ranges from \"0∼10\". The improvement becomes more substantial as the distance increases.",
        "25% improvement",
        "The authors present evidence that the model can capture biases in data annotation and collection through their analysis of errors caused by biased data collection practices (Waseem et al., BIBREF5) and biases in annotation rules (Davidson et al., BIBREF9). The study highlights 11 out of 351 documents being discarded due to annotation biases, demonstrating how the model can identify these issues.",
        "Yes, other baselines were tested to compare with the neural baseline. The non-contextual fastText embeddings were used as the comparison baseline for hashtag segmentation tasks.",
        "270 million tokens",
        "Improvements in F1 for paraphrase identification include using back-translation to create an improved English version of training data. This results in significant improvements for cross-lingual Natural Language Inference (NLI) tasks.",
        "The datasets used in the experiments are:\n- NER datasets: CoNLL2003 and OntoNotes5.0 (English)\n- Chinese datasets: MSRA and OntoNotes4.0 (Chinese)",
        "Born-digital data was presented to the subjects for labeling into two classes.",
        "The evaluation setup includes using lowercase BLEU as the metric for comparison with strong baselines. For NMT translation tasks, it compares performance against baselines like Waseem and Hovy, Davidson et al., and Waseem et al.",
        "Bidirectional GRU networks with Long Short-Term Memory (LSTM) are used as learning models on the dataset.",
        "Neural network architectures used in this context include neural sequence-to-sequence models (both multi-source and monolingual repair systems), language model input strategies such as ELMo-style representations, and variants that use bi-directional models to augment the encoder and uni-directional models for decoding.",
        "Weights are dynamically adjusted based on various techniques such as focal loss, self-paced learning, and meta-networks.",
        "The results show that the proposed Ghost-VLAD pooling approach outperforms previous state-of-the-art methods by an absolute 1.88% F1-score. The experimental evaluation was conducted on fine-tuning strategies for Indian languages and pre-trained BERTbase model compared with official baselines, resulting in improved performance across precision, recall, and weighted-average F1-score metrics.",
        "An individual model consists of predictions averaged over 10 runs and then combined with other models' predictions. If removing an individual model increases the average score, it is considered as a positive change in performance.",
        "Non-standard pronunciation is identified through crowdworkers who analyze text and provide accurate pronunciations based on language-specific rules. For this task, a multilingual corpus consisting of spelling-to-pronunciation pairs extracted from Wiktionary is used instead of a monolingual English resource. The dataset is partitioned into training and test sets for further analysis.",
        "A semicharacter architecture is a specific model design featuring a layered structure with both linear and nonlinear components. In this configuration, neural networks are composed of multiple layers: initially including only linear processing (e.g., using fully connected nodes) before adding non-linear elements to enhance classification or prediction capabilities.",
        "The content explores statistical methods like Gaussian Mixture Models and Frame Selection Decoding or Support Vector Machines (SVM), as well as deep learning approaches related to pun detection across different languages. Specifically, it mentions exploring ways to incorporate richer semantic and linguistic information for detecting puns in various languages, including Chinese.",
        "Overall effective.",
        "No. The data has been de-identified by removing identifying information such as \"de-\" tags and digital zeros, ensuring it cannot be traced back to its original source.",
        "The baseline was referenced to the mid point of the firewall for the developed side panel.",
        "The annotated clinical notes were obtained from the CE task in 2010 i2b2/VA.",
        "Masking words in the decoder helps improve performance on NMT models by providing additional context beyond just word vectors and improving other features like batch norm calculations.",
        "ILPRL dataset",
        "Baseline features and pre-trained features are used.",
        "The dataset was manually labeled by experts for containing fake news or not.",
        "The eight NER (Named Entity Recognition) tasks evaluated included document-level sentiment classification, language modeling, and character-based neural machine translation.",
        "The training data was translated into the target language to enhance performance on the test set.",
        "They used a DocRepair model for their system.",
        "The baseline for this task was a seq2seq model with attention provided by the shared task organizers, which uses an embedding of two adjacent words to receive contextual information.",
        "The baselines compared with in this work are:\n- Name-based Nearest-Neighbor model (NN)\n- Simple Encoder-Decoder baseline with ingredient attention (Enc-Dec)",
        "The political bias of different sources is included by learning parameters for \"INLINEFORM0\" and \"INLINEFORM1.\" The model uses the layer of mentions to convey useful information for classification. To assess robustness, experiments were conducted using only left-biased or right-biased outlets from both disinformation and mainstream domains. Results show significant accuracy in distinguishing mainstream news from disinformation regardless of political bias.",
        "The ancient Chinese dataset comes from internet articles collected in several dynasties (about 1000BC-200BC) written by celebrities.",
        "English",
        "The Chinese datasets used in the experiment were MSRA and OntoNotes4.0.",
        "7",
        "The dataset used in this paper is described and made available at github.com/link-yet-to-be-updated.",
        "The clinical datasets used in the paper are:\n1. MEDDOCAN: Medical Document Anonymization shared task dataset (BIBREF3)\n2. NUBes (a corpus of real medical reports in Spanish) (BIBREF4)",
        "They used traditional linguistic features.",
        "Metrics used to establish that CognIA makes chatbots more knowledgeable and better at learning and conversation include:\n1. Improved ability for the chatbot to know when it is appropriate to answer versus when it's not.\n2. Enhanced social awareness capabilities, allowing the chatbot to assist with financial matters in a group setting.",
        "No.",
        "Galatasaray and Fenerbahçe",
        "Two sets of experiments were conducted:\n- Entity-level sentiment analysis using BIBREF23, BIBREF17, and BIBREF18.\n- Named-entity recognition with BIBREF17, BIBREF19, BIBREF24, BIBREF25, and BIBREF26.",
        "Gaussian-masked directional multi-head attention captures representation by utilizing multi-headed attention with Gaussian masks.",
        "The types of social media that were considered included forums, message boards, legacy social media channels, and modern social media platforms like Twitter.",
        "The network's baseline features outperform pre-trained features and are effective for sarcasm detection.",
        "The hyperparameters that were varied for the experiments on the four tasks are:\n\n- The number of coupling layers (4, 8, 16) for both tasks in the neural projector.",
        "Scores were obtained using a system with i-vectors based on 400 dimensions. The scores were calculated using cosine distance for speaker verification and phrase- and gender-dependent s-norm normalization. The Hybrid IR+RQE QA system had an average score of 0.827, outperforming other systems both in terms of success rate and precision.",
        "20-million token corpora is considered too small to train ELMo models for the word analogy task.",
        "Yes, it is possible to convert cloze-style questions into naturally-looking ones.",
        "They consider NLI tasks.",
        "Their model compares to previous models using audio features and resolves issues with predictions of being incorrect for the neutral class.",
        "These new ELMo embeddings have larger training sets compared to previous ones.",
        "The dataset contains 262,755 ironic sentences and 102,330 non-ironic sentences.",
        "TensorFlow, PyTorch, Keras, SINDy, and others.",
        "Yes, their NER model learns NER from both text and images.",
        "Yes, they evaluate only on English datasets.",
        "Their highest MRR score was achieved in the third test batch set for the Factoid Question Answering task.",
        "The datasets evaluated for experiments are SimpleQuestions, WebQSP, SIGHAN Bakeoff 2005, PKU, MSR, AS, and CITYU. The other evaluations involve English all-words WSD datasets like Senseval-2 (SE2), SE3, SemEval-2007 (SE07), SEM13, and SE15 for WordNet use in the experiment.",
        "The authors evidence this claim by showing that when M > 2 (multiple frameworks/models/optimization techniques), the optimization process often yields denoisers with different γ values (sampling overhead) depending on α distributions. This variability suggests challenges for productivity and optimal solutions in engineer usage, which is directly related to why many engineers find it a big overhead to choose from multiple frameworks, models, and optimization techniques.",
        "MSR, AS"
    ]
}